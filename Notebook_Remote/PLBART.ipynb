{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijO7xaA78tFd",
    "outputId": "1707670a-00f1-4de5-fff2-a02bffa7be52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeT5.ipynb  PLBART.ipynb  Roberta.ipynb  data.jsonl  predictions_codet5.jsonl\r\n",
      "Models\t      PLBModels     codet5.png\t   hubert.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SS4eWkzwE2fg",
    "outputId": "14a05227-2584-4790-a444-095e90ac2e5d"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers --force --ignore-installed PyYAML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4yClB6jP8tFj"
   },
   "outputs": [],
   "source": [
    "# !pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-LwE-je9Dkq",
    "outputId": "0df7e63a-3b29-4ac6-b9d3-3a3805781652"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')\n",
    "# %cd /content/gdrive/Shareddrives/DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qiKW1lqN8tFk"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRHXcSmH27My"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7_M05DJYGolZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, RobertaForSequenceClassification, BertTokenizer\n",
    "from transformers import PLBartTokenizer, PLBartForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fRCo9D022cNP"
   },
   "outputs": [],
   "source": [
    "tc2code = pd.read_json('./data.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "r6PK1SVm3PAB"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYHjwOgb3lQD",
    "outputId": "84db5fc1-53e6-4c79-b81e-e921309672d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            testCode  \\\n",
      "0  /*\\n * This file was automatically generated b...   \n",
      "1  /*\\n * This file was automatically generated b...   \n",
      "2  /*\\n * This file was automatically generated b...   \n",
      "3  /*\\n * This file was automatically generated b...   \n",
      "4  /*\\n * This file was automatically generated b...   \n",
      "\n",
      "                                          sourceCode  \n",
      "0  package macaw.util;\\n\\nimport macaw.system.Mac...  \n",
      "1  package macaw.util;\\n\\nimport macaw.system.Use...  \n",
      "2  package macaw.util;\\n\\nimport java.util.regex....  \n",
      "3  package macaw.util;\\n\\nimport java.awt.event.C...  \n",
      "4  package macaw.util;\\n\\nimport javax.swing.*;\\n...  \n"
     ]
    }
   ],
   "source": [
    "print(tc2code.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtQP-oXd4B4I"
   },
   "source": [
    "Random data Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhYpaqLP-iu7",
    "outputId": "f0fbf9b3-a05c-40e0-92ac-15f5bda82727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /home/harish/anaconda3/lib/python3.7/site-packages (0.1.96)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SqNltSsoL8dj"
   },
   "outputs": [],
   "source": [
    "from transformers import PLBartForConditionalGeneration, PLBartTokenizer, BartTokenizer\n",
    "tokenizer = PLBartTokenizer.from_pretrained(\"uclanlp/plbart-base\",src_lang=\"java\", tgt_lang=\"java\")\n",
    "model = PLBartForConditionalGeneration.from_pretrained(\"uclanlp/plbart-base\").to(device)\n",
    "# model=T5Model.from_pretrained(\"Salesforce/codet5-small\")\n",
    "input_ids = tokenizer(\n",
    "    tc2code['testCode'][0], return_tensors=\"pt\"\n",
    ").input_ids  # Batch size 1\n",
    "decoder_input_ids = tokenizer(tc2code['sourceCode'][0], return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "\n",
    "# forward pass\n",
    "# outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "# last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2Att9pqQiHC",
    "outputId": "8d3e2d3d-9f15-43be-e3ff-2beb8cf42c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated docstring: packagepackagepackagepackagepackagepackagepackagepackagepackagepackagepackagepackage packagepackagepackage package package package package package package package package package package packagepackage;package package package package;package package package packagePackage; }; package package package package package; package\n"
     ]
    }
   ],
   "source": [
    "sample_outputs = model.generate(\n",
    "    input_ids.to(device),\n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=50, \n",
    "    top_p=0.95, \n",
    "    num_return_sequences=3\n",
    ")\n",
    "\n",
    "# outputs = model.generate(input_ids)\n",
    "print(\"Generated docstring:\", tokenizer.decode(sample_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8Sn5y1kp8i8z"
   },
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxsPokUj4lG9"
   },
   "source": [
    "Define Tokenizer and Tokenize the input and op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ee6-ogIg5FHF"
   },
   "outputs": [],
   "source": [
    "# tc2code['token_lengths']=tc2code['sourceCode'].apply(lambda x: len(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MzuAstx96CGU"
   },
   "outputs": [],
   "source": [
    "# tc2code['token_lengths_test']=tc2code['testCode'].apply(lambda x: len(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4P83bFSR7DN9",
    "outputId": "fe4fdf34-2333-434e-dbd7-1d2d81a78dfa"
   },
   "outputs": [],
   "source": [
    "# tc2code['token_lengths'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhDWVtCBC4Zt"
   },
   "source": [
    "The 75th percentile is 1766 hence we choose 1800 as the max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TggHMadh7FVm",
    "outputId": "749f55bd-8d98-4dd0-e661-7d041a5f11c4"
   },
   "outputs": [],
   "source": [
    "# tc2code['token_lengths_test'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxyGEpgZC-BO"
   },
   "source": [
    "The 75th percentile is 745 and 1351 so lets go with 1400 and 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "F1AaslSS495V"
   },
   "outputs": [],
   "source": [
    "def PlBartTokenizerForSeq2Seq(x):\n",
    "  targetSeq=tokenizer(x,max_length=1400,truncation=True,padding='max_length',return_tensors=\"pt\", add_special_tokens = True).input_ids\n",
    "    ## Regularize Cross Entropy loss\n",
    "  #  target_seq_with_ignore_index=[]\n",
    "  #  for seq in targetSeq:\n",
    "  #     targetseq_example = [label if label != 0 else -100 for label in seq]\n",
    "  #     target_seq_with_ignore_index.append(targetseq_example)\n",
    "  #  return torch.Tensor(target_seq_with_ignore_index)\n",
    "  targetSeq[targetSeq==0]=-100\n",
    "  return targetSeq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pDAT2UoiF497"
   },
   "outputs": [],
   "source": [
    "def PLBartTokenizerForSeq2SeqTest(x):\n",
    "  return tokenizer.batch_encode_plus(x,max_length=750,truncation=True,padding='max_length',return_tensors=\"pt\", add_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxBuWHm-9G0a",
    "outputId": "15ca0d34-9da8-411b-8e8d-4fd65ffff129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1886, 4615, 2358,  ...,    1,    1,    1]])\n"
     ]
    }
   ],
   "source": [
    "print(PlBartTokenizerForSeq2Seq(tc2code['sourceCode'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHmlJWEB7jtJ"
   },
   "source": [
    "Report ඞ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "6Lvb5idf7QTu",
    "outputId": "249aba64-7f6d-4560-9252-1cd4de7ff618"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harish/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/harish/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testCode</th>\n",
       "      <th>sourceCode</th>\n",
       "      <th>test_Samples</th>\n",
       "      <th>source_Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport macaw.system.Mac...</td>\n",
       "      <td>[▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...</td>\n",
       "      <td>[▁package, ▁mac, aw, ., util, ;, ▁import, ▁mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport macaw.system.Use...</td>\n",
       "      <td>[▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...</td>\n",
       "      <td>[▁package, ▁mac, aw, ., util, ;, ▁import, ▁mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport java.util.regex....</td>\n",
       "      <td>[▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...</td>\n",
       "      <td>[▁package, ▁mac, aw, ., util, ;, ▁import, java...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport java.awt.event.C...</td>\n",
       "      <td>[▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...</td>\n",
       "      <td>[▁package, ▁mac, aw, ., util, ;, ▁import, java...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport javax.swing.*;\\n...</td>\n",
       "      <td>[▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...</td>\n",
       "      <td>[▁package, ▁mac, aw, ., util, ;, ▁import, java...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport macaw.businessLa...</td>\n",
       "      <td>[▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...</td>\n",
       "      <td>[▁package, ▁mac, aw, ., util, ;, ▁import, ▁mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport macaw.system.Mac...</td>\n",
       "      <td>[▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...</td>\n",
       "      <td>[▁package, ▁mac, aw, ., util, ;, ▁import, ▁mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>/*\\n * Created on 25-Jul-2009\\n * Copyright (C...</td>\n",
       "      <td>[▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...</td>\n",
       "      <td>[▁/*, ▁*, ▁Created, ▁on, ▁25, -, J, ul, -200, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport macaw.system.Mac...</td>\n",
       "      <td>[▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...</td>\n",
       "      <td>[▁package, ▁mac, aw, ., util, ;, ▁import, ▁mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>/*\\n * Created on 25-Jul-2009\\n * Copyright (C...</td>\n",
       "      <td>[▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...</td>\n",
       "      <td>[▁/*, ▁*, ▁Created, ▁on, ▁25, -, J, ul, -200, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            testCode  \\\n",
       "0  /*\\n * This file was automatically generated b...   \n",
       "1  /*\\n * This file was automatically generated b...   \n",
       "2  /*\\n * This file was automatically generated b...   \n",
       "3  /*\\n * This file was automatically generated b...   \n",
       "4  /*\\n * This file was automatically generated b...   \n",
       "5  /*\\n * This file was automatically generated b...   \n",
       "6  /*\\n * This file was automatically generated b...   \n",
       "7  /*\\n * This file was automatically generated b...   \n",
       "8  /*\\n * This file was automatically generated b...   \n",
       "9  /*\\n * This file was automatically generated b...   \n",
       "\n",
       "                                          sourceCode  \\\n",
       "0  package macaw.util;\\n\\nimport macaw.system.Mac...   \n",
       "1  package macaw.util;\\n\\nimport macaw.system.Use...   \n",
       "2  package macaw.util;\\n\\nimport java.util.regex....   \n",
       "3  package macaw.util;\\n\\nimport java.awt.event.C...   \n",
       "4  package macaw.util;\\n\\nimport javax.swing.*;\\n...   \n",
       "5  package macaw.util;\\n\\nimport macaw.businessLa...   \n",
       "6  package macaw.util;\\n\\nimport macaw.system.Mac...   \n",
       "7  /*\\n * Created on 25-Jul-2009\\n * Copyright (C...   \n",
       "8  package macaw.util;\\n\\nimport macaw.system.Mac...   \n",
       "9  /*\\n * Created on 25-Jul-2009\\n * Copyright (C...   \n",
       "\n",
       "                                        test_Samples  \\\n",
       "0  [▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...   \n",
       "1  [▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...   \n",
       "2  [▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...   \n",
       "3  [▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...   \n",
       "4  [▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...   \n",
       "5  [▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...   \n",
       "6  [▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...   \n",
       "7  [▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...   \n",
       "8  [▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...   \n",
       "9  [▁/*, ▁*, ▁This, ▁file, ▁was, ▁automatically, ...   \n",
       "\n",
       "                                      source_Samples  \n",
       "0  [▁package, ▁mac, aw, ., util, ;, ▁import, ▁mac...  \n",
       "1  [▁package, ▁mac, aw, ., util, ;, ▁import, ▁mac...  \n",
       "2  [▁package, ▁mac, aw, ., util, ;, ▁import, java...  \n",
       "3  [▁package, ▁mac, aw, ., util, ;, ▁import, java...  \n",
       "4  [▁package, ▁mac, aw, ., util, ;, ▁import, java...  \n",
       "5  [▁package, ▁mac, aw, ., util, ;, ▁import, ▁mac...  \n",
       "6  [▁package, ▁mac, aw, ., util, ;, ▁import, ▁mac...  \n",
       "7  [▁/*, ▁*, ▁Created, ▁on, ▁25, -, J, ul, -200, ...  \n",
       "8  [▁package, ▁mac, aw, ., util, ;, ▁import, ▁mac...  \n",
       "9  [▁/*, ▁*, ▁Created, ▁on, ▁25, -, J, ul, -200, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_code=tc2code.head(10)\n",
    "sample_code['test_Samples']=sample_code['testCode'].apply(lambda x: tokenizer.tokenize(x))\n",
    "sample_code['source_Samples']=sample_code['sourceCode'].apply(lambda x: tokenizer.tokenize(x))\n",
    "sample_code.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuBrtOXU9moe",
    "outputId": "acebadef-7086-4f9e-c370-4278c3630977"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 4378,   294,   670,  ...,  4038,     2, 50001],\n",
       "        [ 4378,   294,   670,  ...,  4346,     2, 50001],\n",
       "        [ 4378,   294,   670,  ...,     1,     1,     1],\n",
       "        ...,\n",
       "        [ 4378,   294,   670,  ...,     1,     1,     1],\n",
       "        [ 4378,   294,   670,  ...,   866,     2, 50001],\n",
       "        [ 4378,   294,   670,  ...,   866,     2, 50001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PLBartTokenizerForSeq2SeqTest(sample_code['testCode'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxedDAVk_NJX"
   },
   "source": [
    "Training the models hopefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "YF7ZaNvZ7veJ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tc2code['testCode'], tc2code['sourceCode'], test_size=0.2, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8yTfw9ET_s6n"
   },
   "outputs": [],
   "source": [
    "X_train_tensors=PLBartTokenizerForSeq2SeqTest(X_train.to_list())\n",
    "X_test_tensors=PLBartTokenizerForSeq2SeqTest(X_test.to_list())\n",
    "X_val_tensors=PLBartTokenizerForSeq2SeqTest(X_val.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "DsGd1lbCAKlb"
   },
   "outputs": [],
   "source": [
    "y_train_tensors=PlBartTokenizerForSeq2Seq(y_train.to_list())\n",
    "y_test_tensors=PlBartTokenizerForSeq2Seq(y_test.to_list())\n",
    "y_val_tensors=PlBartTokenizerForSeq2Seq(y_val.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "a-2gh9C8BVJH"
   },
   "outputs": [],
   "source": [
    "input_ids_train = X_train_tensors['input_ids']\n",
    "attention_masks_train = X_train_tensors['attention_mask']\n",
    "labels_train = y_train_tensors\n",
    "\n",
    "#validation set\n",
    "input_ids_val = X_val_tensors['input_ids']\n",
    "attention_masks_val = X_val_tensors['attention_mask']\n",
    "labels_val = y_val_tensors\n",
    "\n",
    "\n",
    "input_ids_test = X_test_tensors['input_ids']\n",
    "attention_masks_test = X_test_tensors['attention_mask']\n",
    "labels_test = y_test_tensors\n",
    "expected_source_code=y_test.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "6feqxw73M0mX",
    "outputId": "41a88a15-9446-4ffe-88db-3334aa1836bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/*\\n * Created on 14/mar/2010\\n * Copyright (C) 2010 by Andrea Vacondio.\\n *\\n * This program is free software; you can redistribute it and/or modify it under the terms of the \\n * GNU General Public License as published by the Free Software Foundation; \\n * either version 2 of the License.\\n * This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; \\n * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. \\n * See the GNU General Public License for more details.\\n * You should have received a copy of the GNU General Public License along with this program; \\n * if not, write to the Free Software Foundation, Inc., \\n *  59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\\n */\\npackage org.pdfsam.guiclient.business.listeners;\\n\\nimport java.awt.event.InputEvent;\\nimport java.awt.event.MouseWheelEvent;\\nimport java.awt.event.MouseWheelListener;\\n\\nimport org.pdfsam.guiclient.gui.components.JPreviewImage;\\n\\n/**\\n * Listen for the mouse wheel to perform zoom operations on the\\n * {@link JPreviewImage}\\n * \\n * @author Andrea Vacondio\\n * \\n */\\npublic class MouseWheelZoomListener implements MouseWheelListener {\\n\\n\\tprivate JPreviewImage image;\\n\\n\\t/**\\n\\t * @param image\\n\\t */\\n\\tpublic MouseWheelZoomListener(JPreviewImage image) {\\n\\t\\tsuper();\\n\\t\\tthis.image = image;\\n\\t}\\n\\n\\t/*\\n\\t * (non-Javadoc)\\n\\t * \\n\\t * @seejava.awt.event.MouseWheelListener#mouseWheelMoved(java.awt.event.\\n\\t * MouseWheelEvent)\\n\\t */\\n\\t@Override\\n\\tpublic void mouseWheelMoved(MouseWheelEvent e) {\\n\\t\\tif ((e.getModifiers() & InputEvent.CTRL_MASK) == InputEvent.CTRL_MASK) {\\n\\t\\t\\tif (e.getScrollType() == MouseWheelEvent.WHEEL_UNIT_SCROLL) {\\n\\t\\t\\t\\timage.zoom(e.getWheelRotation());\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}\\n}\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_source_code[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "np4BZ3MzDPst",
    "outputId": "1b58da6e-b978-4a65-d1c4-4647953ed975"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beO5g_Za8tFz",
    "outputId": "03ced298-e6c1-4c51-b935-327e015eee46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeT5.ipynb  PLBART.ipynb  Roberta.ipynb  data.jsonl  predictions_codet5.jsonl\r\n",
      "Models\t      PLBModels     codet5.png\t   hubert.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XKSxIFZDSOk"
   },
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHW995YeDUnL",
    "outputId": "cebc78dd-3f55-4545-bc55-c34621a83fda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PLBartForConditionalGeneration were not initialized from the model checkpoint at uclanlp/plbart-base and are newly initialized because the shapes did not match:\n",
      "- model.encoder.embed_positions.weight: found shape torch.Size([1026, 768]) in the checkpoint and torch.Size([1502, 768]) in the model instantiated\n",
      "- model.decoder.embed_positions.weight: found shape torch.Size([1026, 768]) in the checkpoint and torch.Size([1502, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PLBartForConditionalGeneration(\n",
       "  (model): PLBartModel(\n",
       "    (shared): Embedding(50005, 768, padding_idx=1)\n",
       "    (encoder): PLBartEncoder(\n",
       "      (embed_tokens): Embedding(50005, 768, padding_idx=1)\n",
       "      (embed_positions): PLBartLearnedPositionalEmbedding(1502, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): PLBartEncoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): PLBartEncoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): PLBartEncoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): PLBartEncoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): PLBartEncoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): PLBartEncoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): PLBartDecoder(\n",
       "      (embed_tokens): Embedding(50005, 768, padding_idx=1)\n",
       "      (embed_positions): PLBartLearnedPositionalEmbedding(1502, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): PLBartDecoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): PLBartDecoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): PLBartDecoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): PLBartDecoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): PLBartDecoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): PLBartDecoderLayer(\n",
       "          (self_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): PLBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50005, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plb_model =  PLBartForConditionalGeneration.from_pretrained(\"uclanlp/plbart-base\",max_position_embeddings=1500,ignore_mismatched_sizes=True).to(device)\n",
    "plb_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "QbyPuDvYIjQq"
   },
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, \n",
    "                              attention_masks_train,\n",
    "                              labels_train)\n",
    "\n",
    "dataset_val = TensorDataset(input_ids_val, \n",
    "                             attention_masks_val, \n",
    "                             labels_val)\n",
    "\n",
    "# dataset_test = TensorDataset(input_ids_test, \n",
    "#                              attention_masks_test, \n",
    "#                              labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiSatBfRyv-L"
   },
   "source": [
    "Defining a Custom test loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QH-Hn8Xs9yS",
    "outputId": "8d3d3ac1-67a7-4e56-fbd7-a53340148ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0911,  0.5215, -0.4653],\n",
      "        [ 1.5466,  1.4855,  1.1333]])\n",
      "tensor([ 0.0911,  0.5215, -0.4653])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "tr=torch.randn((2,3))\n",
    "print(tr)\n",
    "print(tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ZVOxDgFRyvMb"
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "class CodeTCDatasetTest(data.Dataset):\n",
    "    def __init__(self, testTensor,sourceTensor,testExpectedCode):\n",
    "      self.testTensor=testTensor\n",
    "      self.sourceTensor=sourceTensor\n",
    "      self.testExpectedCode=testExpectedCode\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.testTensor[index],self.sourceTensor[index],self.testExpectedCode[index]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.testExpectedCode)\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    testTensorList,sourceTensorList,sourceCode = zip(*data)\n",
    "\n",
    "    testTensors = torch.stack(testTensorList, 0)\n",
    "    sourceTensors = torch.stack(sourceTensorList, 0)\n",
    "      \n",
    "    return testTensors, sourceTensors, sourceCode\n",
    "\n",
    "def get_test_loader(testTensor,sourceTensors,sourceCodeList,batch_size):\n",
    "    code2tctest = CodeTCDatasetTest(testTensor,sourceTensors,sourceCodeList)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset=code2tctest, \n",
    "                                              batch_size=batch_size,\n",
    "                                              collate_fn=collate_fn)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3KC16GLEImTA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "#train set\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler = RandomSampler(dataset_train),\n",
    "                              batch_size = batch_size)\n",
    "\n",
    "#validation set\n",
    "dataloader_val = DataLoader(dataset_val,\n",
    "                              sampler = RandomSampler(dataset_val),\n",
    "                              batch_size = batch_size)\n",
    "\n",
    "dataloader_test = get_test_loader(input_ids_test,labels_test,expected_source_code,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9y6eZGrsIql-"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = torch.optim.AdamW(plb_model.parameters(),\n",
    "                 lr = 1e-4,\n",
    "                 eps = 1e-8)\n",
    "                 \n",
    "epochs = 10\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                           num_warmup_steps = 0,\n",
    "                                           num_training_steps = len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "BFwFGwPuI0TF"
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val,model):\n",
    "\n",
    "    #evaluation mode \n",
    "    model.eval()\n",
    "    \n",
    "    #tracking variables\n",
    "    loss_val_total = 0\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        #load into GPU\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        #define inputs\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        #compute logits\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        #compute loss\n",
    "        loss = outputs[0]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "    #compute average loss\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "            \n",
    "    return loss_val_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sc6CGVR58tF1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Ewqvg0THI8f1"
   },
   "outputs": [],
   "source": [
    "def train_model(model,epochs):\n",
    "    save_epoch=2\n",
    "    validation_loss_epochs=[]\n",
    "    training_loss_epochs=[]\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        loss_train_total = 0\n",
    "        \n",
    "#         progress_bar = tqdm(dataloader_train, \n",
    "#                             desc = 'Epoch {:1d}'.format(epoch), \n",
    "#                             leave = True, \n",
    "#                             disable = False)\n",
    "        idx=0\n",
    "        for batch in dataloader_train:\n",
    "            idx+=1\n",
    "            model.zero_grad() #set gradient to 0\n",
    "        \n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            \n",
    "            inputs = {'input_ids': batch[0], \n",
    "                      'attention_mask': batch[1], \n",
    "                      'labels': batch[2]}\n",
    "            \n",
    "            outputs = model(**inputs) #unpack the dict straight into inputs\n",
    "            \n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            if idx%300==0:\n",
    "                print(f'training_loss at epoch:{epoch},iter:{idx}:{(loss.item() / len(batch))}')\n",
    "#             progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "        if epoch%save_epoch==0:    \n",
    "          model.save_pretrained(\"PLBModels\")\n",
    "        \n",
    "        tqdm.write(f'\\n Epoch {epoch}')\n",
    "        \n",
    "        loss_train_ave = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write(f'Training loss: {loss_train_ave}')\n",
    "        \n",
    "        val_loss = evaluate(dataloader_val,model)\n",
    "        validation_loss_epochs.append(val_loss)\n",
    "        training_loss_epochs.append(loss_train_ave)\n",
    "        \n",
    "        tqdm.write(f'Validation loss: {val_loss}') \n",
    "    return validation_loss_epochs,training_loss_epochs,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S72NeeXw8tF2",
    "outputId": "2a2df6fb-e3ef-439f-a726-9685de75accd"
   },
   "outputs": [],
   "source": [
    "# print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "vTXJzVQ-8tF2"
   },
   "outputs": [],
   "source": [
    "training_losses=[]\n",
    "val_losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plb_model.save_pretrained(\"PLBModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PTEB0FlKDaY",
    "outputId": "27092acb-4835-44fd-db28-af3fc6406b18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss at epoch:1,iter:300:0.1506525973478953\n",
      "training_loss at epoch:1,iter:600:0.24319936831792197\n",
      "training_loss at epoch:1,iter:900:0.276054044564565\n",
      "training_loss at epoch:1,iter:1200:0.14614349603652954\n",
      "training_loss at epoch:1,iter:1500:0.10275261600812276\n",
      "training_loss at epoch:1,iter:1800:0.13556523124376932\n",
      "training_loss at epoch:1,iter:2100:0.07891931633154552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [12:09<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1\n",
      "Training loss: 0.6279618555168603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [13:02<1:57:19, 782.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3743462404038044\n",
      "training_loss at epoch:2,iter:300:0.1726357340812683\n",
      "training_loss at epoch:2,iter:600:0.045174395044644676\n",
      "training_loss at epoch:2,iter:900:0.058949634432792664\n",
      "training_loss at epoch:2,iter:1200:0.18641378482182822\n",
      "training_loss at epoch:2,iter:1500:0.1775403618812561\n",
      "training_loss at epoch:2,iter:1800:0.15718640883763632\n",
      "training_loss at epoch:2,iter:2100:0.15624032417933145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [25:12<1:57:19, 782.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 2\n",
      "Training loss: 0.39237714552428077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [26:05<1:44:23, 782.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3439561507198059\n",
      "training_loss at epoch:3,iter:300:0.022785852352778118\n",
      "training_loss at epoch:3,iter:900:0.11205741763114929\n",
      "training_loss at epoch:3,iter:1200:0.12249306837717693\n",
      "training_loss at epoch:3,iter:1500:0.20782033602396646\n",
      "training_loss at epoch:3,iter:1800:0.15623363852500916\n",
      "training_loss at epoch:3,iter:2100:0.061995421846707664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [38:13<1:44:23, 782.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 3\n",
      "Training loss: 0.32490448909943564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [39:06<1:31:13, 781.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.33111663308261213\n",
      "training_loss at epoch:4,iter:300:0.18422450621922812\n",
      "training_loss at epoch:4,iter:600:0.1806310017903646\n",
      "training_loss at epoch:4,iter:900:0.055746336778004967\n",
      "training_loss at epoch:4,iter:1200:0.0696517676115036\n",
      "training_loss at epoch:4,iter:1800:0.13118488589922586\n",
      "training_loss at epoch:4,iter:2100:0.03410762548446655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [51:18<1:31:13, 781.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 4\n",
      "Training loss: 0.27914292609079666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [52:11<1:18:18, 783.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3315281868557404\n",
      "training_loss at epoch:5,iter:300:0.137066384156545\n",
      "training_loss at epoch:5,iter:600:0.0440295934677124\n",
      "training_loss at epoch:5,iter:900:0.15394262472788492\n",
      "training_loss at epoch:5,iter:1200:0.1005061666170756\n",
      "training_loss at epoch:5,iter:1500:0.04036450386047363\n",
      "training_loss at epoch:5,iter:1800:0.02459559092919032\n",
      "training_loss at epoch:5,iter:2100:0.06791134675343831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [1:04:22<1:18:18, 783.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 5\n",
      "Training loss: 0.2438264496474322\n",
      "training_loss at epoch:6,iter:300:0.032660541435082756\n",
      "training_loss at epoch:6,iter:600:0.11098462343215942\n",
      "training_loss at epoch:6,iter:900:0.0903771420319875\n",
      "training_loss at epoch:6,iter:1200:0.042743573586146034\n",
      "training_loss at epoch:6,iter:1500:0.060361762841542564\n",
      "training_loss at epoch:6,iter:1800:0.05576916038990021\n",
      "training_loss at epoch:6,iter:2100:0.1003594199816386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [1:17:23<1:05:17, 783.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 6\n",
      "Training loss: 0.21535889246401607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [1:18:16<52:10, 782.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.33445321971719916\n",
      "training_loss at epoch:7,iter:300:0.05426227549711863\n",
      "training_loss at epoch:7,iter:600:0.1289816896120707\n",
      "training_loss at epoch:7,iter:900:0.04447086652119955\n",
      "training_loss at epoch:7,iter:1200:0.04765619337558746\n",
      "training_loss at epoch:7,iter:1500:0.07080814242362976\n",
      "training_loss at epoch:7,iter:1800:0.07564220825831096\n",
      "training_loss at epoch:7,iter:2100:0.045527552564938865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [1:30:24<52:10, 782.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 7\n",
      "Training loss: 0.19169393998848716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [1:31:16<39:05, 781.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.34012402285690235\n",
      "training_loss at epoch:8,iter:300:0.04583653807640076\n",
      "training_loss at epoch:8,iter:600:0.010975826531648636\n",
      "training_loss at epoch:8,iter:900:0.06703780591487885\n",
      "training_loss at epoch:8,iter:1200:0.030110254883766174\n",
      "training_loss at epoch:8,iter:1500:0.008032325655221939\n",
      "training_loss at epoch:8,iter:1800:0.06284602483113606\n",
      "training_loss at epoch:8,iter:2100:0.15411922335624695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [1:43:28<39:05, 781.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 8\n",
      "Training loss: 0.17221047214611812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [1:44:21<26:05, 782.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3508453625947871\n",
      "training_loss at epoch:9,iter:300:0.04823986689249674\n",
      "training_loss at epoch:9,iter:600:0.04047358532746633\n",
      "training_loss at epoch:9,iter:900:0.1039048433303833\n",
      "training_loss at epoch:9,iter:1200:0.04580524563789368\n",
      "training_loss at epoch:9,iter:1500:0.0196118267873923\n",
      "training_loss at epoch:9,iter:1800:0.07787664731343587\n",
      "training_loss at epoch:9,iter:2100:0.04134619484345118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [1:56:33<26:05, 782.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 9\n",
      "Training loss: 0.15669535473476048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [1:57:26<13:03, 783.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3546604521759935\n",
      "training_loss at epoch:10,iter:300:0.034513793885707855\n",
      "training_loss at epoch:10,iter:600:0.0403887207309405\n",
      "training_loss at epoch:10,iter:900:0.014178141951560974\n",
      "training_loss at epoch:10,iter:1200:0.06092956165472666\n",
      "training_loss at epoch:10,iter:1500:0.05063860615094503\n",
      "training_loss at epoch:10,iter:1800:0.09276092052459717\n",
      "training_loss at epoch:10,iter:2100:0.005995887021223704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [2:09:35<13:03, 783.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 10\n",
      "Training loss: 0.145367099799232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [2:10:27<00:00, 782.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3595451210666902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_losses,training_losses,plb_model=train_model(plb_model,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "gX_40sFWKIm8"
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "lq3iHnbiI8yb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n_epochs=len(training_losses)\n",
    "\n",
    "epochs_arr=np.arange(start=1,stop=n_epochs+1,step=1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epochs_arr,val_losses,label='Validation Loss')\n",
    "plt.plot(epochs_arr,training_losses,label='Training Loss')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.legend()\n",
    "plt.savefig('plbart.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "4t-MOhnsKq-o"
   },
   "outputs": [],
   "source": [
    "def getPredictionsTopK(inputs,model,device):\n",
    "      sample_outputs = model.generate(\n",
    "        inputs.to(device),\n",
    "        do_sample=True, \n",
    "        max_length=1800, \n",
    "        top_k=900, \n",
    "        top_p=0.95, \n",
    "        num_return_sequences=3)\n",
    "    # outputs = model.generate(input_ids)\n",
    "      sequences=[]\n",
    "      for i in range(sample_outputs.shape[0]):\n",
    "        sequences.append(tokenizer.decode(sample_outputs[i], skip_special_tokens=True))\n",
    "      return sequences\n",
    "\n",
    "def getPredictionsGreedy(inputs,model,device):\n",
    "      greedy_output = model.generate(inputs.to(device), max_length=1800)\n",
    "      sequences=[]\n",
    "      for i in range(greedy_output.shape[0]):\n",
    "        sequences.append(tokenizer.decode(greedy_output[i], skip_special_tokens=True))\n",
    "      return sequences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "yf0_fIzz9ZY0"
   },
   "outputs": [],
   "source": [
    "def getPredictedTexts(dataloader_test,genAlgo,model,device):\n",
    "    predictions=[]\n",
    "    allExpectedprogs=[]\n",
    "    idx=0\n",
    "    for ip,eop,estr in dataloader_test:\n",
    "        print(f\"iter{idx} of {len(dataloader_test)}\")\n",
    "        prediction=genAlgo(ip,model,device)\n",
    "        predictions=predictions+prediction\n",
    "        expected=[x for x in estr]\n",
    "        allExpectedprogs=allExpectedprogs+expected\n",
    "        idx+=1\n",
    "    return allExpectedprogs,predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "qJPyaWnDBcbm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0 of 58\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-53f49a41ab0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mallExpectedprogsGreedy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictionsGreedy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetPredictedTexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgetPredictionsGreedy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-0337ff1504d1>\u001b[0m in \u001b[0;36mgetPredictedTexts\u001b[0;34m(dataloader_test, genAlgo, model, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mestr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"iter{idx} of {len(dataloader_test)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenAlgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mexpected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-ee0673eced0b>\u001b[0m in \u001b[0;36mgetPredictionsGreedy\u001b[0;34m(inputs, model, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetPredictionsGreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0mgreedy_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgreedy_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "allExpectedprogsGreedy,predictionsGreedy=getPredictedTexts(dataloader_test,getPredictionsGreedy,plb_model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2G5uUfgrDarO"
   },
   "outputs": [],
   "source": [
    "predictiondf_t5 = pd.DataFrame(list(zip(allExpectedprogsGreedy, predictionsGreedy)), columns =['Expected', 'predictions']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfXy3j8tEpF9"
   },
   "outputs": [],
   "source": [
    "predictiondf_t5.to_json('./predictions_plbart.jsonl',orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtu9P5HkIlk9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cmj3IqJdIl_E"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4o-l3kPLIQhe"
   },
   "outputs": [],
   "source": [
    "plb_model.save_pretrained(\"PLBModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKFUvJ4D8tF4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "PLBART.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
