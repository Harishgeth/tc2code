{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeT5.ipynb  Models  data.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SS4eWkzwE2fg",
    "outputId": "229d6be6-b381-4c81-b89b-aab1ad913c6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "Collecting PyYAML\n",
      "  Using cached PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Processing /home/harish/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9/sacremoses-0.0.53-py3-none-any.whl\n",
      "Collecting requests\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Using cached importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
      "Collecting six\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting idna<4,>=2.5; python_version >= \"3\"\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Using cached pyparsing-3.0.8-py3-none-any.whl (98 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "\u001b[31mERROR: pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: conda 4.12.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: astroid 2.3.3 requires typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\", which is not installed.\u001b[0m\n",
      "Installing collected packages: tokenizers, numpy, filelock, six, joblib, typing-extensions, zipp, importlib-metadata, click, tqdm, regex, sacremoses, charset-normalizer, idna, urllib3, certifi, requests, pyparsing, packaging, PyYAML, huggingface-hub, transformers\n",
      "Successfully installed PyYAML-6.0 certifi-2021.10.8 charset-normalizer-2.0.12 click-8.1.3 filelock-3.6.0 huggingface-hub-0.5.1 idna-3.3 importlib-metadata-4.11.3 joblib-1.1.0 numpy-1.21.6 packaging-21.3 pyparsing-3.0.8 regex-2022.4.24 requests-2.27.1 sacremoses-0.0.53 six-1.16.0 tokenizers-0.12.1 tqdm-4.64.0 transformers-4.18.0 typing-extensions-4.2.0 urllib3-1.26.9 zipp-3.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --force --ignore-installed PyYAML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
      "Collecting torchvision==0.10.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n",
      "Collecting torchaudio==0.9.0\n",
      "  Using cached torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: typing-extensions in /home/harish/anaconda3/lib/python3.7/site-packages (from torch==1.9.0+cu111) (4.2.0)\n",
      "Requirement already satisfied: numpy in /home/harish/anaconda3/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (1.21.6)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/harish/anaconda3/lib/python3.7/site-packages (from torchvision==0.10.0+cu111) (7.0.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n",
      "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRHXcSmH27My"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7_M05DJYGolZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel, RobertaForSequenceClassification, BertTokenizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fRCo9D022cNP"
   },
   "outputs": [],
   "source": [
    "tc2code = pd.read_json('./data.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "r6PK1SVm3PAB"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYHjwOgb3lQD",
    "outputId": "1bf9432a-9728-44ca-e571-47ba9ce6329b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            testCode  \\\n",
      "0  /*\\n * This file was automatically generated b...   \n",
      "1  /*\\n * This file was automatically generated b...   \n",
      "2  /*\\n * This file was automatically generated b...   \n",
      "3  /*\\n * This file was automatically generated b...   \n",
      "4  /*\\n * This file was automatically generated b...   \n",
      "\n",
      "                                          sourceCode  \n",
      "0  package macaw.util;\\n\\nimport macaw.system.Mac...  \n",
      "1  package macaw.util;\\n\\nimport macaw.system.Use...  \n",
      "2  package macaw.util;\\n\\nimport java.util.regex....  \n",
      "3  package macaw.util;\\n\\nimport java.awt.event.C...  \n",
      "4  package macaw.util;\\n\\nimport javax.swing.*;\\n...  \n"
     ]
    }
   ],
   "source": [
    "print(tc2code.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtQP-oXd4B4I"
   },
   "source": [
    "Random data Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278,
     "referenced_widgets": [
      "58ad5efc745d4716b753ec30345a24fe",
      "107c9db3eb394897aa35eeb73aca58a7",
      "a15d541c346441d1990f63b46f3d685a",
      "546f6b6cc5a14708bcf05cfd08fc6351",
      "44e525ce3e704386b61582ba7996bae1",
      "24886985211f40c985a8366c26ba59ae",
      "b6fb9a445be74b2884194f1c059ea953",
      "b6b853d453374652a7108a1c7132dcfb",
      "28ee415f653f4bca892b917cc4d59516",
      "8b3a6015983b459ea85ee1a49ed0d13a",
      "648ad9ff35274fbeaf78df5c3e76fd68",
      "3f9fdc363f934e6bb74be7f574c23de9",
      "19056d6013a140668aca04ee96d20aa2",
      "3c49b3523d05451d802d5b685534e393",
      "79bec1b343964a00846e392859774a1d",
      "e4276c9f591247589623b5ff20449496",
      "fc3d15ead0ec4452b1ad06e029f66fa4",
      "bccf935bc9334a5793a681de4863654e",
      "d63664f79e0646d1926203d08487237a",
      "cf8b4c128350479f9823d3f3243752f7",
      "cb24ad0a76de4e4ca3649809d40437b7",
      "535a2e7f9054416ea6a7aa1e7afcafe1",
      "930ce426da724d4a9cc83dec22f431d8",
      "dbb5cd3f295a46ccb5ebd422cb17dc7d",
      "177c7b72f5494a77a4e99f784b04a140",
      "90ae1f11ae42495c9ee6bdec12a2e6ed",
      "2bea6b92eafb4b299164996975716a4c",
      "f6ac9f486b274a83bdd3eede2dd441de",
      "4bfd289d8eab426c8ab66bba4b470041",
      "78138fd78fc147eeb63d99c19c107379",
      "69b704498b40482b9d5a558267095431",
      "fe47a6270e624095a23cdf87ceb48b27",
      "5bf65953abef4f32a9f9b6fc5b3690ac",
      "e967a52bf1a343bb9395fdf4240a5d9e",
      "0fac156490a94fc6b2656312bb35c921",
      "222def9d04434f529063233f364fa384",
      "04e02a2cb7d146f79089f204ee834620",
      "35f5205d66fb430f9c5456bbf12026f7",
      "33d38ade070b4e1b9baf5683464147f7",
      "7d443f008c12491d81d3e2d6f6f62c46",
      "58e4477f271f4ea7a3dece11b61dc982",
      "a67948a75e8c4753bb3be7f50cb69b2c",
      "e2820c54debe46e686aeb2326f5f5225",
      "350ad93ce7de4b338c8e2055fb166155",
      "18cd4d70e52a490ca646e37935f22b09",
      "e6db17f8a5ea4231be6c63952abc9be0",
      "18a7e10f6da849ad9c95c720dcabd5e7",
      "3c965a35d26842db9fcc8273b9e53d1f",
      "f301256384f44e558759a3e478d4dd4f",
      "45a3a944205e4b439834ba591c73e6b0",
      "cad249f40db1488e84ee61ea700340ee",
      "921bcaed79134ad98ba87bd9a6d3a0a2",
      "a30e5173a933485bbaec0950b8144322",
      "d7c41db284d746b98f3f002bfc51cb1d",
      "073c2abbe9564a529704d8d2c4c1e21a",
      "4bbdb3bf20ae4b0bbcfbecaafdee08fd",
      "9226a0ae61fe4139b1dfcc7b4f3c6048",
      "5a7e1836247642199ab3e8879a571df3",
      "7906838c5de243db9442473d2fcbd810",
      "5151ce33e66a40268675e60adc68a144",
      "6cf5481a6d6b40c2b7b3407dd3986921",
      "dd79760bc72c42beb92e6325725fd97f",
      "aed68e0e0f8a4185956e6d277058c17b",
      "d46e63c37e7a46eabaae89892be902d8",
      "044cbfb13fe243ef8fdc99691bc9df9f",
      "480d94da0fb74e2b99c876a752a1b308",
      "d6f0184c751443a582da1bcaceb4222d",
      "249578c83d2840a19197ab99c0778379",
      "90701ff27c864ffbabfffa91c3b3c37c",
      "483fa124b73641ab90e962a8f07d9edc",
      "90853cbd095c456b8f33f8efd0ef07ba",
      "d2e0c03ae0eb47f5b2f90861e4fa67e6",
      "c0e62fd3d424468ebd4f5b5415710b5d",
      "1dd805a73f9b46949a7cc0cb8152d248",
      "c8afb472ba944bc4bb94192466d9bbc5",
      "6f98f267828b4c4aacc73b06e95bf737",
      "894968a3a1b4400b890bedb0a478dde0"
     ]
    },
    "id": "SqNltSsoL8dj",
    "outputId": "5f8238d3-cea7-4f1b-c8d1-a9676fa52eb0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a81e2e32964367b2f0fa30bf351e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/687k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22757aedc6bb4b1c9210f4e6b683d4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/287k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd6383e396f4e67b6b685cef97e2499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5befc0d5b7b34e93ad8807d17766d091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/12.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cb84ef840d49d885055f8ac08bf354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43efa00775624442b3e6666ebe841cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc953ed70c7242ab875283b0874e6cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1021 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5Model,T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\").to(device)\n",
    "# model=T5Model.from_pretrained(\"Salesforce/codet5-small\")\n",
    "input_ids = tokenizer(\n",
    "    tc2code['testCode'][0], return_tensors=\"pt\"\n",
    ").input_ids  # Batch size 1\n",
    "decoder_input_ids = tokenizer(tc2code['sourceCode'][0], return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "\n",
    "# forward pass\n",
    "# outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "# last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2Att9pqQiHC",
    "outputId": "4b7add5b-59e8-4da1-9a48-ac34d013b24d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated docstring:  public}if (label == \"Labellabelfalse ; if}\n",
      "{\n",
      "}\n",
      "public voidthis {({\n",
      "(;;{\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_outputs = model.generate(\n",
    "    input_ids.to(device),\n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=50, \n",
    "    top_p=0.95, \n",
    "    num_return_sequences=3\n",
    ")\n",
    "\n",
    "# outputs = model.generate(input_ids)\n",
    "print(\"Generated docstring:\", tokenizer.decode(sample_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8Sn5y1kp8i8z"
   },
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxsPokUj4lG9"
   },
   "source": [
    "Define Tokenizer and Tokenize the input and op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ee6-ogIg5FHF"
   },
   "outputs": [],
   "source": [
    "# tc2code['token_lengths']=tc2code['sourceCode'].apply(lambda x: len(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MzuAstx96CGU"
   },
   "outputs": [],
   "source": [
    "# tc2code['token_lengths_test']=tc2code['testCode'].apply(lambda x: len(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4P83bFSR7DN9",
    "outputId": "ed7825bb-e366-40c1-ed22-3e417410b266"
   },
   "outputs": [],
   "source": [
    "# tc2code['token_lengths'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhDWVtCBC4Zt"
   },
   "source": [
    "The 75th percentile is 1766 hence we choose 1800 as the max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TggHMadh7FVm",
    "outputId": "29e59294-ac3b-43f1-aa13-8ddc9355d1f8"
   },
   "outputs": [],
   "source": [
    "# tc2code['token_lengths_test'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxyGEpgZC-BO"
   },
   "source": [
    "The 75th percentile is 972 so lets go with 1766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "F1AaslSS495V"
   },
   "outputs": [],
   "source": [
    "def RobertaTokenizerForSeq2Seq(x):\n",
    "  targetSeq=tokenizer(x,max_length=1800,truncation=True,padding='max_length',return_tensors=\"pt\", add_special_tokens = True).input_ids\n",
    "    ## Regularize Cross Entropy loss\n",
    "  #  target_seq_with_ignore_index=[]\n",
    "  #  for seq in targetSeq:\n",
    "  #     targetseq_example = [label if label != 0 else -100 for label in seq]\n",
    "  #     target_seq_with_ignore_index.append(targetseq_example)\n",
    "  #  return torch.Tensor(target_seq_with_ignore_index)\n",
    "  targetSeq[targetSeq==0]=-100\n",
    "  return targetSeq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pDAT2UoiF497"
   },
   "outputs": [],
   "source": [
    "def RobertaTokenizerForSeq2SeqTest(x):\n",
    "  return tokenizer.batch_encode_plus(x,max_length=1000,truncation=True,padding='max_length',return_tensors=\"pt\", add_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxBuWHm-9G0a",
    "outputId": "0e97bfbf-0cd7-4e06-9da3-66c731bf1170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1, 5610, 5318,  ..., -100, -100, -100]])\n"
     ]
    }
   ],
   "source": [
    "print(RobertaTokenizerForSeq2Seq(tc2code['sourceCode'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHmlJWEB7jtJ"
   },
   "source": [
    "Report ඞ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 814
    },
    "id": "6Lvb5idf7QTu",
    "outputId": "87f9a6e5-4247-4032-aa3c-5398bce87e71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harish/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/harish/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testCode</th>\n",
       "      <th>sourceCode</th>\n",
       "      <th>test_Samples</th>\n",
       "      <th>source_Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport macaw.system.Mac...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...</td>\n",
       "      <td>[package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport macaw.system.Use...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...</td>\n",
       "      <td>[package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport java.util.regex....</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...</td>\n",
       "      <td>[package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport java.awt.event.C...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...</td>\n",
       "      <td>[package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport javax.swing.*;\\n...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...</td>\n",
       "      <td>[package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport macaw.businessLa...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...</td>\n",
       "      <td>[package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport macaw.system.Mac...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...</td>\n",
       "      <td>[package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>/*\\n * Created on 25-Jul-2009\\n * Copyright (C...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠCreated, Ġon, Ġ25, -, J, ul, -, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>package macaw.util;\\n\\nimport macaw.system.Mac...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...</td>\n",
       "      <td>[package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/*\\n * This file was automatically generated b...</td>\n",
       "      <td>/*\\n * Created on 25-Jul-2009\\n * Copyright (C...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...</td>\n",
       "      <td>[/*, Ċ, Ġ*, ĠCreated, Ġon, Ġ25, -, J, ul, -, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            testCode  \\\n",
       "0  /*\\n * This file was automatically generated b...   \n",
       "1  /*\\n * This file was automatically generated b...   \n",
       "2  /*\\n * This file was automatically generated b...   \n",
       "3  /*\\n * This file was automatically generated b...   \n",
       "4  /*\\n * This file was automatically generated b...   \n",
       "5  /*\\n * This file was automatically generated b...   \n",
       "6  /*\\n * This file was automatically generated b...   \n",
       "7  /*\\n * This file was automatically generated b...   \n",
       "8  /*\\n * This file was automatically generated b...   \n",
       "9  /*\\n * This file was automatically generated b...   \n",
       "\n",
       "                                          sourceCode  \\\n",
       "0  package macaw.util;\\n\\nimport macaw.system.Mac...   \n",
       "1  package macaw.util;\\n\\nimport macaw.system.Use...   \n",
       "2  package macaw.util;\\n\\nimport java.util.regex....   \n",
       "3  package macaw.util;\\n\\nimport java.awt.event.C...   \n",
       "4  package macaw.util;\\n\\nimport javax.swing.*;\\n...   \n",
       "5  package macaw.util;\\n\\nimport macaw.businessLa...   \n",
       "6  package macaw.util;\\n\\nimport macaw.system.Mac...   \n",
       "7  /*\\n * Created on 25-Jul-2009\\n * Copyright (C...   \n",
       "8  package macaw.util;\\n\\nimport macaw.system.Mac...   \n",
       "9  /*\\n * Created on 25-Jul-2009\\n * Copyright (C...   \n",
       "\n",
       "                                        test_Samples  \\\n",
       "0  [/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...   \n",
       "1  [/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...   \n",
       "2  [/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...   \n",
       "3  [/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...   \n",
       "4  [/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...   \n",
       "5  [/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...   \n",
       "6  [/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...   \n",
       "7  [/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...   \n",
       "8  [/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...   \n",
       "9  [/*, Ċ, Ġ*, ĠThis, Ġfile, Ġwas, Ġautomatically...   \n",
       "\n",
       "                                      source_Samples  \n",
       "0  [package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...  \n",
       "1  [package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...  \n",
       "2  [package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...  \n",
       "3  [package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...  \n",
       "4  [package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...  \n",
       "5  [package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...  \n",
       "6  [package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...  \n",
       "7  [/*, Ċ, Ġ*, ĠCreated, Ġon, Ġ25, -, J, ul, -, 2...  \n",
       "8  [package, Ġmac, aw, ., util, ;, Ċ, Ċ, import, ...  \n",
       "9  [/*, Ċ, Ġ*, ĠCreated, Ġon, Ġ25, -, J, ul, -, 2...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_code=tc2code.head(10)\n",
    "sample_code['test_Samples']=sample_code['testCode'].apply(lambda x: tokenizer.tokenize(x))\n",
    "sample_code['source_Samples']=sample_code['sourceCode'].apply(lambda x: tokenizer.tokenize(x))\n",
    "sample_code.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuBrtOXU9moe",
    "outputId": "d6658671-dafb-4000-c1c7-c98ec9e0e56a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 20308,   203,  ...,    67,  1919,     2],\n",
       "        [    1, 20308,   203,  ...,   225,  1071,     2],\n",
       "        [    1, 20308,   203,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    1, 20308,   203,  ...,     0,     0,     0],\n",
       "        [    1, 20308,   203,  ...,   225,  1071,     2],\n",
       "        [    1, 20308,   203,  ...,   225,  1071,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RobertaTokenizerForSeq2SeqTest(sample_code['testCode'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxedDAVk_NJX"
   },
   "source": [
    "Training the models hopefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "YF7ZaNvZ7veJ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tc2code['testCode'], tc2code['sourceCode'], test_size=0.2, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "8yTfw9ET_s6n"
   },
   "outputs": [],
   "source": [
    "X_train_tensors=RobertaTokenizerForSeq2SeqTest(X_train.to_list())\n",
    "X_test_tensors=RobertaTokenizerForSeq2SeqTest(X_test.to_list())\n",
    "X_val_tensors=RobertaTokenizerForSeq2SeqTest(X_val.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "DsGd1lbCAKlb"
   },
   "outputs": [],
   "source": [
    "y_train_tensors=RobertaTokenizerForSeq2Seq(y_train.to_list())\n",
    "y_test_tensors=RobertaTokenizerForSeq2Seq(y_test.to_list())\n",
    "y_val_tensors=RobertaTokenizerForSeq2Seq(y_val.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "a-2gh9C8BVJH"
   },
   "outputs": [],
   "source": [
    "input_ids_train = X_train_tensors['input_ids']\n",
    "attention_masks_train = X_train_tensors['attention_mask']\n",
    "labels_train = y_train_tensors\n",
    "\n",
    "#validation set\n",
    "input_ids_val = X_val_tensors['input_ids']\n",
    "attention_masks_val = X_val_tensors['attention_mask']\n",
    "labels_val = y_val_tensors\n",
    "\n",
    "\n",
    "input_ids_test = X_test_tensors['input_ids']\n",
    "attention_masks_test = X_test_tensors['attention_mask']\n",
    "labels_test = y_test_tensors\n",
    "expected_source_code=y_test.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "6feqxw73M0mX",
    "outputId": "4579ddf2-4011-45a9-899a-82fff7d539af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/*\\n * Created on 14/mar/2010\\n * Copyright (C) 2010 by Andrea Vacondio.\\n *\\n * This program is free software; you can redistribute it and/or modify it under the terms of the \\n * GNU General Public License as published by the Free Software Foundation; \\n * either version 2 of the License.\\n * This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; \\n * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. \\n * See the GNU General Public License for more details.\\n * You should have received a copy of the GNU General Public License along with this program; \\n * if not, write to the Free Software Foundation, Inc., \\n *  59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\\n */\\npackage org.pdfsam.guiclient.business.listeners;\\n\\nimport java.awt.event.InputEvent;\\nimport java.awt.event.MouseWheelEvent;\\nimport java.awt.event.MouseWheelListener;\\n\\nimport org.pdfsam.guiclient.gui.components.JPreviewImage;\\n\\n/**\\n * Listen for the mouse wheel to perform zoom operations on the\\n * {@link JPreviewImage}\\n * \\n * @author Andrea Vacondio\\n * \\n */\\npublic class MouseWheelZoomListener implements MouseWheelListener {\\n\\n\\tprivate JPreviewImage image;\\n\\n\\t/**\\n\\t * @param image\\n\\t */\\n\\tpublic MouseWheelZoomListener(JPreviewImage image) {\\n\\t\\tsuper();\\n\\t\\tthis.image = image;\\n\\t}\\n\\n\\t/*\\n\\t * (non-Javadoc)\\n\\t * \\n\\t * @seejava.awt.event.MouseWheelListener#mouseWheelMoved(java.awt.event.\\n\\t * MouseWheelEvent)\\n\\t */\\n\\t@Override\\n\\tpublic void mouseWheelMoved(MouseWheelEvent e) {\\n\\t\\tif ((e.getModifiers() & InputEvent.CTRL_MASK) == InputEvent.CTRL_MASK) {\\n\\t\\t\\tif (e.getScrollType() == MouseWheelEvent.WHEEL_UNIT_SCROLL) {\\n\\t\\t\\t\\timage.zoom(e.getWheelRotation());\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}\\n}\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_source_code[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "np4BZ3MzDPst",
    "outputId": "591a32ce-04e1-4fb5-b10e-74c1b06de04a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XKSxIFZDSOk"
   },
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHW995YeDUnL",
    "outputId": "38ba535b-36b9-4aa9-9d46-1b48b1e45d0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Salesforce/codet5-small and are newly initialized because the shapes did not match:\n",
      "- shared.weight: found shape torch.Size([32100, 512]) in the checkpoint and torch.Size([32100, 1850]) in the model instantiated\n",
      "- encoder.embed_tokens.weight: found shape torch.Size([32100, 512]) in the checkpoint and torch.Size([32100, 1850]) in the model instantiated\n",
      "- encoder.block.0.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.0.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.0.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.0.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- encoder.block.0.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.0.layer.1.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- encoder.block.0.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- encoder.block.0.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.1.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.1.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.1.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.1.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- encoder.block.1.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.1.layer.1.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- encoder.block.1.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- encoder.block.1.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.2.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.2.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.2.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.2.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- encoder.block.2.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.2.layer.1.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- encoder.block.2.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- encoder.block.2.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.3.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.3.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.3.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.3.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- encoder.block.3.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.3.layer.1.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- encoder.block.3.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- encoder.block.3.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.4.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.4.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.4.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.4.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- encoder.block.4.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.4.layer.1.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- encoder.block.4.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- encoder.block.4.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.5.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.5.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.5.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- encoder.block.5.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- encoder.block.5.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.block.5.layer.1.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- encoder.block.5.layer.1.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- encoder.block.5.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- encoder.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.embed_tokens.weight: found shape torch.Size([32100, 512]) in the checkpoint and torch.Size([32100, 1850]) in the model instantiated\n",
      "- decoder.block.0.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.0.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.0.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.0.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.0.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.0.layer.1.EncDecAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.0.layer.1.EncDecAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.0.layer.1.EncDecAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.0.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.0.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.0.layer.2.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- decoder.block.0.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- decoder.block.0.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.1.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.1.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.1.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.1.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.1.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.1.layer.1.EncDecAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.1.layer.1.EncDecAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.1.layer.1.EncDecAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.1.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.1.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.1.layer.2.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- decoder.block.1.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- decoder.block.1.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.2.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.2.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.2.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.2.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.2.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.2.layer.1.EncDecAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.2.layer.1.EncDecAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.2.layer.1.EncDecAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.2.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.2.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.2.layer.2.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- decoder.block.2.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- decoder.block.2.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.3.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.3.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.3.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.3.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.3.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.3.layer.1.EncDecAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.3.layer.1.EncDecAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.3.layer.1.EncDecAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.3.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.3.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.3.layer.2.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- decoder.block.3.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- decoder.block.3.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.4.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.4.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.4.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.4.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.4.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.4.layer.1.EncDecAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.4.layer.1.EncDecAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.4.layer.1.EncDecAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.4.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.4.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.4.layer.2.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- decoder.block.4.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- decoder.block.4.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.5.layer.0.SelfAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.5.layer.0.SelfAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.5.layer.0.SelfAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.5.layer.0.SelfAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.5.layer.0.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.5.layer.1.EncDecAttention.q.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.5.layer.1.EncDecAttention.k.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.5.layer.1.EncDecAttention.v.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([512, 1850]) in the model instantiated\n",
      "- decoder.block.5.layer.1.EncDecAttention.o.weight: found shape torch.Size([512, 512]) in the checkpoint and torch.Size([1850, 512]) in the model instantiated\n",
      "- decoder.block.5.layer.1.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.block.5.layer.2.DenseReluDense.wi.weight: found shape torch.Size([2048, 512]) in the checkpoint and torch.Size([2048, 1850]) in the model instantiated\n",
      "- decoder.block.5.layer.2.DenseReluDense.wo.weight: found shape torch.Size([512, 2048]) in the checkpoint and torch.Size([1850, 2048]) in the model instantiated\n",
      "- decoder.block.5.layer.2.layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- decoder.final_layer_norm.weight: found shape torch.Size([512]) in the checkpoint and torch.Size([1850]) in the model instantiated\n",
      "- lm_head.weight: found shape torch.Size([32100, 512]) in the checkpoint and torch.Size([32100, 1850]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32100, 1850)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 1850)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32100, 1850)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=1850, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=1850, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=1850, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=1850, bias=False)\n",
       "              (dropout): Dropout(p=0.5, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1850, out_features=32100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\",dropout_rate=0.5,d_model=1850,ignore_mismatched_sizes=True).to(device)\n",
    "t5_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "QbyPuDvYIjQq"
   },
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, \n",
    "                              attention_masks_train,\n",
    "                              labels_train)\n",
    "\n",
    "dataset_val = TensorDataset(input_ids_val, \n",
    "                             attention_masks_val, \n",
    "                             labels_val)\n",
    "\n",
    "# dataset_test = TensorDataset(input_ids_test, \n",
    "#                              attention_masks_test, \n",
    "#                              labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiSatBfRyv-L"
   },
   "source": [
    "Defining a Custom test loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QH-Hn8Xs9yS",
    "outputId": "9e3985d3-8b99-4eab-edf0-0c36a0d7c0cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1515, -1.5568,  1.1424],\n",
      "        [ 0.6822, -0.2215,  1.3309]])\n",
      "tensor([-0.1515, -1.5568,  1.1424])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "tr=torch.randn((2,3))\n",
    "print(tr)\n",
    "print(tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ZVOxDgFRyvMb"
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "class CodeTCDatasetTest(data.Dataset):\n",
    "    def __init__(self, testTensor,sourceTensor,testExpectedCode):\n",
    "      self.testTensor=testTensor\n",
    "      self.sourceTensor=sourceTensor\n",
    "      self.testExpectedCode=testExpectedCode\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.testTensor[index],self.sourceTensor[index],self.testExpectedCode[index]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.testExpectedCode)\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    testTensorList,sourceTensorList,sourceCode = zip(*data)\n",
    "\n",
    "    testTensors = torch.stack(testTensorList, 0)\n",
    "    sourceTensors = torch.stack(sourceTensorList, 0)\n",
    "      \n",
    "    return testTensors, sourceTensors, sourceCode\n",
    "\n",
    "def get_test_loader(testTensor,sourceTensors,sourceCodeList,batch_size):\n",
    "    \"\"\"Returns torch.utils.data.DataLoader for custom coco dataset.\"\"\"\n",
    "    # COCO caption dataset\n",
    "    code2tctest = CodeTCDatasetTest(testTensor,sourceTensors,sourceCodeList)\n",
    "    \n",
    "    # Data loader for COCO dataset\n",
    "    # This will return (images, captions, lengths) for each iteration.\n",
    "    # images: a tensor of shape (batch_size, 3, 224, 224).\n",
    "    # captions: a tensor of shape (batch_size, padded_length).\n",
    "    # lengths: a list indicating valid length for each caption. length is (batch_size).\n",
    "    data_loader = torch.utils.data.DataLoader(dataset=code2tctest, \n",
    "                                              batch_size=batch_size,\n",
    "                                              collate_fn=collate_fn)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "3KC16GLEImTA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "#train set\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler = RandomSampler(dataset_train),\n",
    "                              batch_size = batch_size)\n",
    "\n",
    "#validation set\n",
    "dataloader_val = DataLoader(dataset_val,\n",
    "                              sampler = RandomSampler(dataset_val),\n",
    "                              batch_size = batch_size)\n",
    "\n",
    "dataloader_test = get_test_loader(input_ids_test,labels_test,expected_source_code,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "9y6eZGrsIql-"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = torch.optim.AdamW(t5_model.parameters(),\n",
    "                 lr = 1e-5,\n",
    "                 eps = 1e-8)\n",
    "                 \n",
    "epochs = 30\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                           num_warmup_steps = 0,\n",
    "                                           num_training_steps = len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "BFwFGwPuI0TF"
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val,model):\n",
    "\n",
    "    #evaluation mode \n",
    "    model.eval()\n",
    "    \n",
    "    #tracking variables\n",
    "    loss_val_total = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        #load into GPU\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        #define inputs\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        #compute logits\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        #compute loss\n",
    "        loss = outputs[0]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "    #compute average loss\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "            \n",
    "    return loss_val_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Ewqvg0THI8f1"
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    save_epoch=5\n",
    "    validation_loss_epochs=[]\n",
    "    training_loss_epochs=[]\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        loss_train_total = 0\n",
    "        \n",
    "        progress_bar = tqdm(dataloader_train, \n",
    "                            desc = 'Epoch {:1d}'.format(epoch), \n",
    "                            leave = False, \n",
    "                            disable = False)\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            \n",
    "            model.zero_grad() #set gradient to 0\n",
    "        \n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            \n",
    "            inputs = {'input_ids': batch[0], \n",
    "                      'attention_mask': batch[1], \n",
    "                      'labels': batch[2]}\n",
    "            \n",
    "            outputs = model(**inputs) #unpack the dict straight into inputs\n",
    "            \n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "        if epoch%save_epoch==0:    \n",
    "          torch.save(model.state_dict(), f'Models/ CodeT5_ft_epoch{epoch}.model')\n",
    "        \n",
    "        tqdm.write('\\n Epoch {epoch}')\n",
    "        \n",
    "        loss_train_ave = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write('Training loss: {loss_train_avg}')\n",
    "        \n",
    "        val_loss = evaluate(dataloader_val,model)\n",
    "        validation_loss_epochs.append(val_loss)\n",
    "        training_loss_epochs.append(loss_train_ave)\n",
    "        \n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        return validation_loss_epochs,training_loss_epochs,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8PTEB0FlKDaY",
    "outputId": "bdcd188b-03e8-45ab-a400-b1f40a46a5d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/2295 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:   0%|          | 0/2295 [00:00<?, ?it/s, training_loss=5.900]\u001b[A\n",
      "Epoch 1:   0%|          | 1/2295 [00:00<23:48,  1.61it/s, training_loss=5.900]\u001b[A\n",
      "Epoch 1:   0%|          | 1/2295 [00:01<23:48,  1.61it/s, training_loss=5.914]\u001b[A\n",
      "Epoch 1:   0%|          | 2/2295 [00:01<22:43,  1.68it/s, training_loss=5.914]\u001b[A\n",
      "Epoch 1:   0%|          | 2/2295 [00:01<22:43,  1.68it/s, training_loss=5.971]\u001b[A\n",
      "Epoch 1:   0%|          | 3/2295 [00:01<22:21,  1.71it/s, training_loss=5.971]\u001b[A\n",
      "Epoch 1:   0%|          | 3/2295 [00:02<22:21,  1.71it/s, training_loss=5.812]\u001b[A\n",
      "Epoch 1:   0%|          | 4/2295 [00:02<22:10,  1.72it/s, training_loss=5.812]\u001b[A\n",
      "Epoch 1:   0%|          | 4/2295 [00:02<22:10,  1.72it/s, training_loss=5.872]\u001b[A\n",
      "Epoch 1:   0%|          | 5/2295 [00:02<22:02,  1.73it/s, training_loss=5.872]\u001b[A\n",
      "Epoch 1:   0%|          | 5/2295 [00:03<22:02,  1.73it/s, training_loss=5.843]\u001b[A\n",
      "Epoch 1:   0%|          | 6/2295 [00:03<21:57,  1.74it/s, training_loss=5.843]\u001b[A\n",
      "Epoch 1:   0%|          | 6/2295 [00:04<21:57,  1.74it/s, training_loss=5.725]\u001b[A\n",
      "Epoch 1:   0%|          | 7/2295 [00:04<21:53,  1.74it/s, training_loss=5.725]\u001b[A\n",
      "Epoch 1:   0%|          | 7/2295 [00:04<21:53,  1.74it/s, training_loss=5.828]\u001b[A\n",
      "Epoch 1:   0%|          | 8/2295 [00:04<21:49,  1.75it/s, training_loss=5.828]\u001b[A\n",
      "Epoch 1:   0%|          | 8/2295 [00:05<21:49,  1.75it/s, training_loss=5.702]\u001b[A\n",
      "Epoch 1:   0%|          | 9/2295 [00:05<21:45,  1.75it/s, training_loss=5.702]\u001b[A\n",
      "Epoch 1:   0%|          | 9/2295 [00:05<21:45,  1.75it/s, training_loss=5.706]\u001b[A\n",
      "Epoch 1:   0%|          | 10/2295 [00:05<21:43,  1.75it/s, training_loss=5.706]\u001b[A\n",
      "Epoch 1:   0%|          | 10/2295 [00:06<21:43,  1.75it/s, training_loss=5.695]\u001b[A\n",
      "Epoch 1:   0%|          | 11/2295 [00:06<21:44,  1.75it/s, training_loss=5.695]\u001b[A\n",
      "Epoch 1:   0%|          | 11/2295 [00:06<21:44,  1.75it/s, training_loss=5.529]\u001b[A\n",
      "Epoch 1:   1%|          | 12/2295 [00:06<21:46,  1.75it/s, training_loss=5.529]\u001b[A\n",
      "Epoch 1:   1%|          | 12/2295 [00:07<21:46,  1.75it/s, training_loss=5.581]\u001b[A\n",
      "Epoch 1:   1%|          | 13/2295 [00:07<21:45,  1.75it/s, training_loss=5.581]\u001b[A\n",
      "Epoch 1:   1%|          | 13/2295 [00:08<21:45,  1.75it/s, training_loss=5.595]\u001b[A\n",
      "Epoch 1:   1%|          | 14/2295 [00:08<21:46,  1.75it/s, training_loss=5.595]\u001b[A\n",
      "Epoch 1:   1%|          | 14/2295 [00:08<21:46,  1.75it/s, training_loss=5.658]\u001b[A\n",
      "Epoch 1:   1%|          | 15/2295 [00:08<21:46,  1.75it/s, training_loss=5.658]\u001b[A\n",
      "Epoch 1:   1%|          | 15/2295 [00:09<21:46,  1.75it/s, training_loss=5.480]\u001b[A\n",
      "Epoch 1:   1%|          | 16/2295 [00:09<21:47,  1.74it/s, training_loss=5.480]\u001b[A\n",
      "Epoch 1:   1%|          | 16/2295 [00:09<21:47,  1.74it/s, training_loss=5.447]\u001b[A\n",
      "Epoch 1:   1%|          | 17/2295 [00:09<21:49,  1.74it/s, training_loss=5.447]\u001b[A\n",
      "Epoch 1:   1%|          | 17/2295 [00:10<21:49,  1.74it/s, training_loss=5.500]\u001b[A\n",
      "Epoch 1:   1%|          | 18/2295 [00:10<21:50,  1.74it/s, training_loss=5.500]\u001b[A\n",
      "Epoch 1:   1%|          | 18/2295 [00:10<21:50,  1.74it/s, training_loss=5.263]\u001b[A\n",
      "Epoch 1:   1%|          | 19/2295 [00:10<21:46,  1.74it/s, training_loss=5.263]\u001b[A\n",
      "Epoch 1:   1%|          | 19/2295 [00:11<21:46,  1.74it/s, training_loss=5.325]\u001b[A\n",
      "Epoch 1:   1%|          | 20/2295 [00:11<21:43,  1.74it/s, training_loss=5.325]\u001b[A\n",
      "Epoch 1:   1%|          | 20/2295 [00:12<21:43,  1.74it/s, training_loss=5.225]\u001b[A\n",
      "Epoch 1:   1%|          | 21/2295 [00:12<21:43,  1.74it/s, training_loss=5.225]\u001b[A\n",
      "Epoch 1:   1%|          | 21/2295 [00:12<21:43,  1.74it/s, training_loss=5.267]\u001b[A\n",
      "Epoch 1:   1%|          | 22/2295 [00:12<21:39,  1.75it/s, training_loss=5.267]\u001b[A\n",
      "Epoch 1:   1%|          | 22/2295 [00:13<21:39,  1.75it/s, training_loss=5.038]\u001b[A\n",
      "Epoch 1:   1%|          | 23/2295 [00:13<21:34,  1.76it/s, training_loss=5.038]\u001b[A\n",
      "Epoch 1:   1%|          | 23/2295 [00:13<21:34,  1.76it/s, training_loss=4.990]\u001b[A\n",
      "Epoch 1:   1%|          | 24/2295 [00:13<21:34,  1.75it/s, training_loss=4.990]\u001b[A\n",
      "Epoch 1:   1%|          | 24/2295 [00:14<21:34,  1.75it/s, training_loss=4.949]\u001b[A\n",
      "Epoch 1:   1%|          | 25/2295 [00:14<21:34,  1.75it/s, training_loss=4.949]\u001b[A\n",
      "Epoch 1:   1%|          | 25/2295 [00:14<21:34,  1.75it/s, training_loss=4.936]\u001b[A\n",
      "Epoch 1:   1%|          | 26/2295 [00:14<21:33,  1.75it/s, training_loss=4.936]\u001b[A\n",
      "Epoch 1:   1%|          | 26/2295 [00:15<21:33,  1.75it/s, training_loss=4.745]\u001b[A\n",
      "Epoch 1:   1%|          | 27/2295 [00:15<21:32,  1.75it/s, training_loss=4.745]\u001b[A\n",
      "Epoch 1:   1%|          | 27/2295 [00:16<21:32,  1.75it/s, training_loss=4.667]\u001b[A\n",
      "Epoch 1:   1%|          | 28/2295 [00:16<21:33,  1.75it/s, training_loss=4.667]\u001b[A\n",
      "Epoch 1:   1%|          | 28/2295 [00:16<21:33,  1.75it/s, training_loss=4.605]\u001b[A\n",
      "Epoch 1:   1%|▏         | 29/2295 [00:16<21:33,  1.75it/s, training_loss=4.605]\u001b[A\n",
      "Epoch 1:   1%|▏         | 29/2295 [00:17<21:33,  1.75it/s, training_loss=4.473]\u001b[A\n",
      "Epoch 1:   1%|▏         | 30/2295 [00:17<21:33,  1.75it/s, training_loss=4.473]\u001b[A\n",
      "Epoch 1:   1%|▏         | 30/2295 [00:17<21:33,  1.75it/s, training_loss=4.441]\u001b[A\n",
      "Epoch 1:   1%|▏         | 31/2295 [00:17<21:34,  1.75it/s, training_loss=4.441]\u001b[A\n",
      "Epoch 1:   1%|▏         | 31/2295 [00:18<21:34,  1.75it/s, training_loss=4.289]\u001b[A\n",
      "Epoch 1:   1%|▏         | 32/2295 [00:18<21:36,  1.75it/s, training_loss=4.289]\u001b[A\n",
      "Epoch 1:   1%|▏         | 32/2295 [00:18<21:36,  1.75it/s, training_loss=4.165]\u001b[A\n",
      "Epoch 1:   1%|▏         | 33/2295 [00:18<21:38,  1.74it/s, training_loss=4.165]\u001b[A\n",
      "Epoch 1:   1%|▏         | 33/2295 [00:19<21:38,  1.74it/s, training_loss=4.086]\u001b[A\n",
      "Epoch 1:   1%|▏         | 34/2295 [00:19<21:34,  1.75it/s, training_loss=4.086]\u001b[A\n",
      "Epoch 1:   1%|▏         | 34/2295 [00:20<21:34,  1.75it/s, training_loss=4.048]\u001b[A\n",
      "Epoch 1:   2%|▏         | 35/2295 [00:20<21:36,  1.74it/s, training_loss=4.048]\u001b[A\n",
      "Epoch 1:   2%|▏         | 35/2295 [00:20<21:36,  1.74it/s, training_loss=3.951]\u001b[A\n",
      "Epoch 1:   2%|▏         | 36/2295 [00:20<21:36,  1.74it/s, training_loss=3.951]\u001b[A\n",
      "Epoch 1:   2%|▏         | 36/2295 [00:21<21:36,  1.74it/s, training_loss=3.927]\u001b[A\n",
      "Epoch 1:   2%|▏         | 37/2295 [00:21<21:33,  1.75it/s, training_loss=3.927]\u001b[A\n",
      "Epoch 1:   2%|▏         | 37/2295 [00:21<21:33,  1.75it/s, training_loss=3.855]\u001b[A\n",
      "Epoch 1:   2%|▏         | 38/2295 [00:21<21:32,  1.75it/s, training_loss=3.855]\u001b[A\n",
      "Epoch 1:   2%|▏         | 38/2295 [00:22<21:32,  1.75it/s, training_loss=3.699]\u001b[A\n",
      "Epoch 1:   2%|▏         | 39/2295 [00:22<21:30,  1.75it/s, training_loss=3.699]\u001b[A\n",
      "Epoch 1:   2%|▏         | 39/2295 [00:22<21:30,  1.75it/s, training_loss=3.665]\u001b[A\n",
      "Epoch 1:   2%|▏         | 40/2295 [00:22<21:32,  1.75it/s, training_loss=3.665]\u001b[A\n",
      "Epoch 1:   2%|▏         | 40/2295 [00:23<21:32,  1.75it/s, training_loss=3.600]\u001b[A\n",
      "Epoch 1:   2%|▏         | 41/2295 [00:23<21:31,  1.75it/s, training_loss=3.600]\u001b[A\n",
      "Epoch 1:   2%|▏         | 41/2295 [00:24<21:31,  1.75it/s, training_loss=3.648]\u001b[A\n",
      "Epoch 1:   2%|▏         | 42/2295 [00:24<21:31,  1.74it/s, training_loss=3.648]\u001b[A\n",
      "Epoch 1:   2%|▏         | 42/2295 [00:24<21:31,  1.74it/s, training_loss=3.573]\u001b[A\n",
      "Epoch 1:   2%|▏         | 43/2295 [00:24<21:30,  1.75it/s, training_loss=3.573]\u001b[A\n",
      "Epoch 1:   2%|▏         | 43/2295 [00:25<21:30,  1.75it/s, training_loss=3.527]\u001b[A\n",
      "Epoch 1:   2%|▏         | 44/2295 [00:25<21:29,  1.75it/s, training_loss=3.527]\u001b[A\n",
      "Epoch 1:   2%|▏         | 44/2295 [00:25<21:29,  1.75it/s, training_loss=3.466]\u001b[A\n",
      "Epoch 1:   2%|▏         | 45/2295 [00:25<21:29,  1.75it/s, training_loss=3.466]\u001b[A\n",
      "Epoch 1:   2%|▏         | 45/2295 [00:26<21:29,  1.75it/s, training_loss=3.420]\u001b[A\n",
      "Epoch 1:   2%|▏         | 46/2295 [00:26<21:30,  1.74it/s, training_loss=3.420]\u001b[A\n",
      "Epoch 1:   2%|▏         | 46/2295 [00:26<21:30,  1.74it/s, training_loss=3.380]\u001b[A\n",
      "Epoch 1:   2%|▏         | 47/2295 [00:26<21:31,  1.74it/s, training_loss=3.380]\u001b[A\n",
      "Epoch 1:   2%|▏         | 47/2295 [00:27<21:31,  1.74it/s, training_loss=3.375]\u001b[A\n",
      "Epoch 1:   2%|▏         | 48/2295 [00:27<21:29,  1.74it/s, training_loss=3.375]\u001b[A\n",
      "Epoch 1:   2%|▏         | 48/2295 [00:28<21:29,  1.74it/s, training_loss=3.388]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 49/2295 [00:28<21:30,  1.74it/s, training_loss=3.388]\u001b[A\n",
      "Epoch 1:   2%|▏         | 49/2295 [00:28<21:30,  1.74it/s, training_loss=3.266]\u001b[A\n",
      "Epoch 1:   2%|▏         | 50/2295 [00:28<21:29,  1.74it/s, training_loss=3.266]\u001b[A\n",
      "Epoch 1:   2%|▏         | 50/2295 [00:29<21:29,  1.74it/s, training_loss=3.326]\u001b[A\n",
      "Epoch 1:   2%|▏         | 51/2295 [00:29<21:27,  1.74it/s, training_loss=3.326]\u001b[A\n",
      "Epoch 1:   2%|▏         | 51/2295 [00:29<21:27,  1.74it/s, training_loss=3.327]\u001b[A\n",
      "Epoch 1:   2%|▏         | 52/2295 [00:29<21:26,  1.74it/s, training_loss=3.327]\u001b[A\n",
      "Epoch 1:   2%|▏         | 52/2295 [00:30<21:26,  1.74it/s, training_loss=3.259]\u001b[A\n",
      "Epoch 1:   2%|▏         | 53/2295 [00:30<21:25,  1.74it/s, training_loss=3.259]\u001b[A\n",
      "Epoch 1:   2%|▏         | 53/2295 [00:30<21:25,  1.74it/s, training_loss=3.231]\u001b[A\n",
      "Epoch 1:   2%|▏         | 54/2295 [00:30<21:26,  1.74it/s, training_loss=3.231]\u001b[A\n",
      "Epoch 1:   2%|▏         | 54/2295 [00:31<21:26,  1.74it/s, training_loss=3.267]\u001b[A\n",
      "Epoch 1:   2%|▏         | 55/2295 [00:31<21:26,  1.74it/s, training_loss=3.267]\u001b[A\n",
      "Epoch 1:   2%|▏         | 55/2295 [00:32<21:26,  1.74it/s, training_loss=3.283]\u001b[A\n",
      "Epoch 1:   2%|▏         | 56/2295 [00:32<21:24,  1.74it/s, training_loss=3.283]\u001b[A\n",
      "Epoch 1:   2%|▏         | 56/2295 [00:32<21:24,  1.74it/s, training_loss=3.330]\u001b[A\n",
      "Epoch 1:   2%|▏         | 57/2295 [00:32<21:26,  1.74it/s, training_loss=3.330]\u001b[A\n",
      "Epoch 1:   2%|▏         | 57/2295 [00:33<21:26,  1.74it/s, training_loss=3.281]\u001b[A\n",
      "Epoch 1:   3%|▎         | 58/2295 [00:33<21:23,  1.74it/s, training_loss=3.281]\u001b[A\n",
      "Epoch 1:   3%|▎         | 58/2295 [00:33<21:23,  1.74it/s, training_loss=3.205]\u001b[A\n",
      "Epoch 1:   3%|▎         | 59/2295 [00:33<21:21,  1.74it/s, training_loss=3.205]\u001b[A\n",
      "Epoch 1:   3%|▎         | 59/2295 [00:34<21:21,  1.74it/s, training_loss=3.198]\u001b[A\n",
      "Epoch 1:   3%|▎         | 60/2295 [00:34<21:20,  1.75it/s, training_loss=3.198]\u001b[A\n",
      "Epoch 1:   3%|▎         | 60/2295 [00:34<21:20,  1.75it/s, training_loss=3.226]\u001b[A\n",
      "Epoch 1:   3%|▎         | 61/2295 [00:34<21:19,  1.75it/s, training_loss=3.226]\u001b[A\n",
      "Epoch 1:   3%|▎         | 61/2295 [00:35<21:19,  1.75it/s, training_loss=3.114]\u001b[A\n",
      "Epoch 1:   3%|▎         | 62/2295 [00:35<21:17,  1.75it/s, training_loss=3.114]\u001b[A\n",
      "Epoch 1:   3%|▎         | 62/2295 [00:36<21:17,  1.75it/s, training_loss=3.157]\u001b[A\n",
      "Epoch 1:   3%|▎         | 63/2295 [00:36<21:15,  1.75it/s, training_loss=3.157]\u001b[A\n",
      "Epoch 1:   3%|▎         | 63/2295 [00:36<21:15,  1.75it/s, training_loss=3.198]\u001b[A\n",
      "Epoch 1:   3%|▎         | 64/2295 [00:36<21:14,  1.75it/s, training_loss=3.198]\u001b[A\n",
      "Epoch 1:   3%|▎         | 64/2295 [00:37<21:14,  1.75it/s, training_loss=3.175]\u001b[A\n",
      "Epoch 1:   3%|▎         | 65/2295 [00:37<21:14,  1.75it/s, training_loss=3.175]\u001b[A\n",
      "Epoch 1:   3%|▎         | 65/2295 [00:37<21:14,  1.75it/s, training_loss=3.169]\u001b[A\n",
      "Epoch 1:   3%|▎         | 66/2295 [00:37<21:15,  1.75it/s, training_loss=3.169]\u001b[A\n",
      "Epoch 1:   3%|▎         | 66/2295 [00:38<21:15,  1.75it/s, training_loss=3.200]\u001b[A\n",
      "Epoch 1:   3%|▎         | 67/2295 [00:38<21:16,  1.75it/s, training_loss=3.200]\u001b[A\n",
      "Epoch 1:   3%|▎         | 67/2295 [00:38<21:16,  1.75it/s, training_loss=3.070]\u001b[A\n",
      "Epoch 1:   3%|▎         | 68/2295 [00:38<21:16,  1.74it/s, training_loss=3.070]\u001b[A\n",
      "Epoch 1:   3%|▎         | 68/2295 [00:39<21:16,  1.74it/s, training_loss=3.111]\u001b[A\n",
      "Epoch 1:   3%|▎         | 69/2295 [00:39<21:18,  1.74it/s, training_loss=3.111]\u001b[A\n",
      "Epoch 1:   3%|▎         | 69/2295 [00:40<21:18,  1.74it/s, training_loss=3.116]\u001b[A\n",
      "Epoch 1:   3%|▎         | 70/2295 [00:40<21:16,  1.74it/s, training_loss=3.116]\u001b[A\n",
      "Epoch 1:   3%|▎         | 70/2295 [00:40<21:16,  1.74it/s, training_loss=3.149]\u001b[A\n",
      "Epoch 1:   3%|▎         | 71/2295 [00:40<21:14,  1.74it/s, training_loss=3.149]\u001b[A\n",
      "Epoch 1:   3%|▎         | 71/2295 [00:41<21:14,  1.74it/s, training_loss=3.101]\u001b[A\n",
      "Epoch 1:   3%|▎         | 72/2295 [00:41<21:15,  1.74it/s, training_loss=3.101]\u001b[A\n",
      "Epoch 1:   3%|▎         | 72/2295 [00:41<21:15,  1.74it/s, training_loss=3.106]\u001b[A\n",
      "Epoch 1:   3%|▎         | 73/2295 [00:41<21:11,  1.75it/s, training_loss=3.106]\u001b[A\n",
      "Epoch 1:   3%|▎         | 73/2295 [00:42<21:11,  1.75it/s, training_loss=3.007]\u001b[A\n",
      "Epoch 1:   3%|▎         | 74/2295 [00:42<21:11,  1.75it/s, training_loss=3.007]\u001b[A\n",
      "Epoch 1:   3%|▎         | 74/2295 [00:43<21:11,  1.75it/s, training_loss=3.026]\u001b[A\n",
      "Epoch 1:   3%|▎         | 75/2295 [00:43<21:10,  1.75it/s, training_loss=3.026]\u001b[A\n",
      "Epoch 1:   3%|▎         | 75/2295 [00:43<21:10,  1.75it/s, training_loss=2.966]\u001b[A\n",
      "Epoch 1:   3%|▎         | 76/2295 [00:43<21:08,  1.75it/s, training_loss=2.966]\u001b[A\n",
      "Epoch 1:   3%|▎         | 76/2295 [00:44<21:08,  1.75it/s, training_loss=2.977]\u001b[A\n",
      "Epoch 1:   3%|▎         | 77/2295 [00:44<21:08,  1.75it/s, training_loss=2.977]\u001b[A\n",
      "Epoch 1:   3%|▎         | 77/2295 [00:44<21:08,  1.75it/s, training_loss=2.954]\u001b[A\n",
      "Epoch 1:   3%|▎         | 78/2295 [00:44<21:08,  1.75it/s, training_loss=2.954]\u001b[A\n",
      "Epoch 1:   3%|▎         | 78/2295 [00:45<21:08,  1.75it/s, training_loss=3.022]\u001b[A\n",
      "Epoch 1:   3%|▎         | 79/2295 [00:45<21:06,  1.75it/s, training_loss=3.022]\u001b[A\n",
      "Epoch 1:   3%|▎         | 79/2295 [00:45<21:06,  1.75it/s, training_loss=3.084]\u001b[A\n",
      "Epoch 1:   3%|▎         | 80/2295 [00:45<21:06,  1.75it/s, training_loss=3.084]\u001b[A\n",
      "Epoch 1:   3%|▎         | 80/2295 [00:46<21:06,  1.75it/s, training_loss=2.989]\u001b[A\n",
      "Epoch 1:   4%|▎         | 81/2295 [00:46<21:06,  1.75it/s, training_loss=2.989]\u001b[A\n",
      "Epoch 1:   4%|▎         | 81/2295 [00:47<21:06,  1.75it/s, training_loss=3.043]\u001b[A\n",
      "Epoch 1:   4%|▎         | 82/2295 [00:47<21:05,  1.75it/s, training_loss=3.043]\u001b[A\n",
      "Epoch 1:   4%|▎         | 82/2295 [00:47<21:05,  1.75it/s, training_loss=2.922]\u001b[A\n",
      "Epoch 1:   4%|▎         | 83/2295 [00:47<21:04,  1.75it/s, training_loss=2.922]\u001b[A\n",
      "Epoch 1:   4%|▎         | 83/2295 [00:48<21:04,  1.75it/s, training_loss=2.956]\u001b[A\n",
      "Epoch 1:   4%|▎         | 84/2295 [00:48<21:03,  1.75it/s, training_loss=2.956]\u001b[A\n",
      "Epoch 1:   4%|▎         | 84/2295 [00:48<21:03,  1.75it/s, training_loss=2.926]\u001b[A\n",
      "Epoch 1:   4%|▎         | 85/2295 [00:48<21:02,  1.75it/s, training_loss=2.926]\u001b[A\n",
      "Epoch 1:   4%|▎         | 85/2295 [00:49<21:02,  1.75it/s, training_loss=3.004]\u001b[A\n",
      "Epoch 1:   4%|▎         | 86/2295 [00:49<21:03,  1.75it/s, training_loss=3.004]\u001b[A\n",
      "Epoch 1:   4%|▎         | 86/2295 [00:49<21:03,  1.75it/s, training_loss=2.948]\u001b[A\n",
      "Epoch 1:   4%|▍         | 87/2295 [00:49<21:05,  1.75it/s, training_loss=2.948]\u001b[A\n",
      "Epoch 1:   4%|▍         | 87/2295 [00:50<21:05,  1.75it/s, training_loss=2.938]\u001b[A\n",
      "Epoch 1:   4%|▍         | 88/2295 [00:50<21:06,  1.74it/s, training_loss=2.938]\u001b[A\n",
      "Epoch 1:   4%|▍         | 88/2295 [00:51<21:06,  1.74it/s, training_loss=2.928]\u001b[A\n",
      "Epoch 1:   4%|▍         | 89/2295 [00:51<21:06,  1.74it/s, training_loss=2.928]\u001b[A\n",
      "Epoch 1:   4%|▍         | 89/2295 [00:51<21:06,  1.74it/s, training_loss=2.954]\u001b[A\n",
      "Epoch 1:   4%|▍         | 90/2295 [00:51<21:04,  1.74it/s, training_loss=2.954]\u001b[A\n",
      "Epoch 1:   4%|▍         | 90/2295 [00:52<21:04,  1.74it/s, training_loss=2.962]\u001b[A\n",
      "Epoch 1:   4%|▍         | 91/2295 [00:52<21:06,  1.74it/s, training_loss=2.962]\u001b[A\n",
      "Epoch 1:   4%|▍         | 91/2295 [00:52<21:06,  1.74it/s, training_loss=2.862]\u001b[A\n",
      "Epoch 1:   4%|▍         | 92/2295 [00:52<21:06,  1.74it/s, training_loss=2.862]\u001b[A\n",
      "Epoch 1:   4%|▍         | 92/2295 [00:53<21:06,  1.74it/s, training_loss=2.902]\u001b[A\n",
      "Epoch 1:   4%|▍         | 93/2295 [00:53<21:05,  1.74it/s, training_loss=2.902]\u001b[A\n",
      "Epoch 1:   4%|▍         | 93/2295 [00:53<21:05,  1.74it/s, training_loss=2.928]\u001b[A\n",
      "Epoch 1:   4%|▍         | 94/2295 [00:53<21:04,  1.74it/s, training_loss=2.928]\u001b[A\n",
      "Epoch 1:   4%|▍         | 94/2295 [00:54<21:04,  1.74it/s, training_loss=2.905]\u001b[A\n",
      "Epoch 1:   4%|▍         | 95/2295 [00:54<21:02,  1.74it/s, training_loss=2.905]\u001b[A\n",
      "Epoch 1:   4%|▍         | 95/2295 [00:55<21:02,  1.74it/s, training_loss=2.948]\u001b[A\n",
      "Epoch 1:   4%|▍         | 96/2295 [00:55<21:05,  1.74it/s, training_loss=2.948]\u001b[A\n",
      "Epoch 1:   4%|▍         | 96/2295 [00:55<21:05,  1.74it/s, training_loss=3.046]\u001b[A\n",
      "Epoch 1:   4%|▍         | 97/2295 [00:55<21:03,  1.74it/s, training_loss=3.046]\u001b[A\n",
      "Epoch 1:   4%|▍         | 97/2295 [00:56<21:03,  1.74it/s, training_loss=2.911]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 98/2295 [00:56<21:02,  1.74it/s, training_loss=2.911]\u001b[A\n",
      "Epoch 1:   4%|▍         | 98/2295 [00:56<21:02,  1.74it/s, training_loss=2.881]\u001b[A\n",
      "Epoch 1:   4%|▍         | 99/2295 [00:56<21:01,  1.74it/s, training_loss=2.881]\u001b[A\n",
      "Epoch 1:   4%|▍         | 99/2295 [00:57<21:01,  1.74it/s, training_loss=2.817]\u001b[A\n",
      "Epoch 1:   4%|▍         | 100/2295 [00:57<20:58,  1.74it/s, training_loss=2.817]\u001b[A\n",
      "Epoch 1:   4%|▍         | 100/2295 [00:57<20:58,  1.74it/s, training_loss=2.977]\u001b[A\n",
      "Epoch 1:   4%|▍         | 101/2295 [00:57<20:57,  1.74it/s, training_loss=2.977]\u001b[A\n",
      "Epoch 1:   4%|▍         | 101/2295 [00:58<20:57,  1.74it/s, training_loss=2.965]\u001b[A\n",
      "Epoch 1:   4%|▍         | 102/2295 [00:58<20:55,  1.75it/s, training_loss=2.965]\u001b[A\n",
      "Epoch 1:   4%|▍         | 102/2295 [00:59<20:55,  1.75it/s, training_loss=2.884]\u001b[A\n",
      "Epoch 1:   4%|▍         | 103/2295 [00:59<20:55,  1.75it/s, training_loss=2.884]\u001b[A\n",
      "Epoch 1:   4%|▍         | 103/2295 [00:59<20:55,  1.75it/s, training_loss=2.961]\u001b[A\n",
      "Epoch 1:   5%|▍         | 104/2295 [00:59<20:55,  1.75it/s, training_loss=2.961]\u001b[A\n",
      "Epoch 1:   5%|▍         | 104/2295 [01:00<20:55,  1.75it/s, training_loss=2.821]\u001b[A\n",
      "Epoch 1:   5%|▍         | 105/2295 [01:00<20:50,  1.75it/s, training_loss=2.821]\u001b[A\n",
      "Epoch 1:   5%|▍         | 105/2295 [01:00<20:50,  1.75it/s, training_loss=2.958]\u001b[A\n",
      "Epoch 1:   5%|▍         | 106/2295 [01:00<20:52,  1.75it/s, training_loss=2.958]\u001b[A\n",
      "Epoch 1:   5%|▍         | 106/2295 [01:01<20:52,  1.75it/s, training_loss=2.846]\u001b[A\n",
      "Epoch 1:   5%|▍         | 107/2295 [01:01<20:52,  1.75it/s, training_loss=2.846]\u001b[A\n",
      "Epoch 1:   5%|▍         | 107/2295 [01:01<20:52,  1.75it/s, training_loss=2.879]\u001b[A\n",
      "Epoch 1:   5%|▍         | 108/2295 [01:01<20:51,  1.75it/s, training_loss=2.879]\u001b[A\n",
      "Epoch 1:   5%|▍         | 108/2295 [01:02<20:51,  1.75it/s, training_loss=2.816]\u001b[A\n",
      "Epoch 1:   5%|▍         | 109/2295 [01:02<20:52,  1.75it/s, training_loss=2.816]\u001b[A\n",
      "Epoch 1:   5%|▍         | 109/2295 [01:03<20:52,  1.75it/s, training_loss=2.837]\u001b[A\n",
      "Epoch 1:   5%|▍         | 110/2295 [01:03<20:51,  1.75it/s, training_loss=2.837]\u001b[A\n",
      "Epoch 1:   5%|▍         | 110/2295 [01:03<20:51,  1.75it/s, training_loss=2.972]\u001b[A\n",
      "Epoch 1:   5%|▍         | 111/2295 [01:03<20:49,  1.75it/s, training_loss=2.972]\u001b[A\n",
      "Epoch 1:   5%|▍         | 111/2295 [01:04<20:49,  1.75it/s, training_loss=2.834]\u001b[A\n",
      "Epoch 1:   5%|▍         | 112/2295 [01:04<20:47,  1.75it/s, training_loss=2.834]\u001b[A\n",
      "Epoch 1:   5%|▍         | 112/2295 [01:04<20:47,  1.75it/s, training_loss=2.886]\u001b[A\n",
      "Epoch 1:   5%|▍         | 113/2295 [01:04<20:46,  1.75it/s, training_loss=2.886]\u001b[A\n",
      "Epoch 1:   5%|▍         | 113/2295 [01:05<20:46,  1.75it/s, training_loss=2.868]\u001b[A\n",
      "Epoch 1:   5%|▍         | 114/2295 [01:05<20:44,  1.75it/s, training_loss=2.868]\u001b[A\n",
      "Epoch 1:   5%|▍         | 114/2295 [01:05<20:44,  1.75it/s, training_loss=2.986]\u001b[A\n",
      "Epoch 1:   5%|▌         | 115/2295 [01:05<20:43,  1.75it/s, training_loss=2.986]\u001b[A\n",
      "Epoch 1:   5%|▌         | 115/2295 [01:06<20:43,  1.75it/s, training_loss=2.883]\u001b[A\n",
      "Epoch 1:   5%|▌         | 116/2295 [01:06<20:42,  1.75it/s, training_loss=2.883]\u001b[A\n",
      "Epoch 1:   5%|▌         | 116/2295 [01:07<20:42,  1.75it/s, training_loss=2.842]\u001b[A\n",
      "Epoch 1:   5%|▌         | 117/2295 [01:07<20:41,  1.75it/s, training_loss=2.842]\u001b[A\n",
      "Epoch 1:   5%|▌         | 117/2295 [01:07<20:41,  1.75it/s, training_loss=2.761]\u001b[A\n",
      "Epoch 1:   5%|▌         | 118/2295 [01:07<20:40,  1.76it/s, training_loss=2.761]\u001b[A\n",
      "Epoch 1:   5%|▌         | 118/2295 [01:08<20:40,  1.76it/s, training_loss=2.811]\u001b[A\n",
      "Epoch 1:   5%|▌         | 119/2295 [01:08<20:39,  1.76it/s, training_loss=2.811]\u001b[A\n",
      "Epoch 1:   5%|▌         | 119/2295 [01:08<20:39,  1.76it/s, training_loss=2.863]\u001b[A\n",
      "Epoch 1:   5%|▌         | 120/2295 [01:08<20:39,  1.75it/s, training_loss=2.863]\u001b[A\n",
      "Epoch 1:   5%|▌         | 120/2295 [01:09<20:39,  1.75it/s, training_loss=2.798]\u001b[A\n",
      "Epoch 1:   5%|▌         | 121/2295 [01:09<20:40,  1.75it/s, training_loss=2.798]\u001b[A\n",
      "Epoch 1:   5%|▌         | 121/2295 [01:09<20:40,  1.75it/s, training_loss=2.841]\u001b[A\n",
      "Epoch 1:   5%|▌         | 122/2295 [01:09<20:39,  1.75it/s, training_loss=2.841]\u001b[A\n",
      "Epoch 1:   5%|▌         | 122/2295 [01:10<20:39,  1.75it/s, training_loss=2.758]\u001b[A\n",
      "Epoch 1:   5%|▌         | 123/2295 [01:10<20:39,  1.75it/s, training_loss=2.758]\u001b[A\n",
      "Epoch 1:   5%|▌         | 123/2295 [01:11<20:39,  1.75it/s, training_loss=2.831]\u001b[A\n",
      "Epoch 1:   5%|▌         | 124/2295 [01:11<20:39,  1.75it/s, training_loss=2.831]\u001b[A\n",
      "Epoch 1:   5%|▌         | 124/2295 [01:11<20:39,  1.75it/s, training_loss=2.880]\u001b[A\n",
      "Epoch 1:   5%|▌         | 125/2295 [01:11<20:39,  1.75it/s, training_loss=2.880]\u001b[A\n",
      "Epoch 1:   5%|▌         | 125/2295 [01:12<20:39,  1.75it/s, training_loss=2.868]\u001b[A\n",
      "Epoch 1:   5%|▌         | 126/2295 [01:12<20:39,  1.75it/s, training_loss=2.868]\u001b[A\n",
      "Epoch 1:   5%|▌         | 126/2295 [01:12<20:39,  1.75it/s, training_loss=2.840]\u001b[A\n",
      "Epoch 1:   6%|▌         | 127/2295 [01:12<20:38,  1.75it/s, training_loss=2.840]\u001b[A\n",
      "Epoch 1:   6%|▌         | 127/2295 [01:13<20:38,  1.75it/s, training_loss=2.758]\u001b[A\n",
      "Epoch 1:   6%|▌         | 128/2295 [01:13<20:38,  1.75it/s, training_loss=2.758]\u001b[A\n",
      "Epoch 1:   6%|▌         | 128/2295 [01:13<20:38,  1.75it/s, training_loss=2.917]\u001b[A\n",
      "Epoch 1:   6%|▌         | 129/2295 [01:13<20:38,  1.75it/s, training_loss=2.917]\u001b[A\n",
      "Epoch 1:   6%|▌         | 129/2295 [01:14<20:38,  1.75it/s, training_loss=2.703]\u001b[A\n",
      "Epoch 1:   6%|▌         | 130/2295 [01:14<20:37,  1.75it/s, training_loss=2.703]\u001b[A\n",
      "Epoch 1:   6%|▌         | 130/2295 [01:15<20:37,  1.75it/s, training_loss=2.789]\u001b[A\n",
      "Epoch 1:   6%|▌         | 131/2295 [01:15<20:37,  1.75it/s, training_loss=2.789]\u001b[A\n",
      "Epoch 1:   6%|▌         | 131/2295 [01:15<20:37,  1.75it/s, training_loss=2.813]\u001b[A\n",
      "Epoch 1:   6%|▌         | 132/2295 [01:15<20:38,  1.75it/s, training_loss=2.813]\u001b[A\n",
      "Epoch 1:   6%|▌         | 132/2295 [01:16<20:38,  1.75it/s, training_loss=2.858]\u001b[A\n",
      "Epoch 1:   6%|▌         | 133/2295 [01:16<20:36,  1.75it/s, training_loss=2.858]\u001b[A\n",
      "Epoch 1:   6%|▌         | 133/2295 [01:16<20:36,  1.75it/s, training_loss=2.710]\u001b[A\n",
      "Epoch 1:   6%|▌         | 134/2295 [01:16<20:34,  1.75it/s, training_loss=2.710]\u001b[A\n",
      "Epoch 1:   6%|▌         | 134/2295 [01:17<20:34,  1.75it/s, training_loss=2.777]\u001b[A\n",
      "Epoch 1:   6%|▌         | 135/2295 [01:17<20:34,  1.75it/s, training_loss=2.777]\u001b[A\n",
      "Epoch 1:   6%|▌         | 135/2295 [01:17<20:34,  1.75it/s, training_loss=2.727]\u001b[A\n",
      "Epoch 1:   6%|▌         | 136/2295 [01:17<20:35,  1.75it/s, training_loss=2.727]\u001b[A\n",
      "Epoch 1:   6%|▌         | 136/2295 [01:18<20:35,  1.75it/s, training_loss=2.803]\u001b[A\n",
      "Epoch 1:   6%|▌         | 137/2295 [01:18<20:34,  1.75it/s, training_loss=2.803]\u001b[A\n",
      "Epoch 1:   6%|▌         | 137/2295 [01:19<20:34,  1.75it/s, training_loss=2.771]\u001b[A\n",
      "Epoch 1:   6%|▌         | 138/2295 [01:19<20:33,  1.75it/s, training_loss=2.771]\u001b[A\n",
      "Epoch 1:   6%|▌         | 138/2295 [01:19<20:33,  1.75it/s, training_loss=2.722]\u001b[A\n",
      "Epoch 1:   6%|▌         | 139/2295 [01:19<20:33,  1.75it/s, training_loss=2.722]\u001b[A\n",
      "Epoch 1:   6%|▌         | 139/2295 [01:20<20:33,  1.75it/s, training_loss=2.723]\u001b[A\n",
      "Epoch 1:   6%|▌         | 140/2295 [01:20<20:32,  1.75it/s, training_loss=2.723]\u001b[A\n",
      "Epoch 1:   6%|▌         | 140/2295 [01:20<20:32,  1.75it/s, training_loss=2.790]\u001b[A\n",
      "Epoch 1:   6%|▌         | 141/2295 [01:20<20:32,  1.75it/s, training_loss=2.790]\u001b[A\n",
      "Epoch 1:   6%|▌         | 141/2295 [01:21<20:32,  1.75it/s, training_loss=2.800]\u001b[A\n",
      "Epoch 1:   6%|▌         | 142/2295 [01:21<20:31,  1.75it/s, training_loss=2.800]\u001b[A\n",
      "Epoch 1:   6%|▌         | 142/2295 [01:21<20:31,  1.75it/s, training_loss=2.783]\u001b[A\n",
      "Epoch 1:   6%|▌         | 143/2295 [01:21<20:31,  1.75it/s, training_loss=2.783]\u001b[A\n",
      "Epoch 1:   6%|▌         | 143/2295 [01:22<20:31,  1.75it/s, training_loss=2.691]\u001b[A\n",
      "Epoch 1:   6%|▋         | 144/2295 [01:22<20:29,  1.75it/s, training_loss=2.691]\u001b[A\n",
      "Epoch 1:   6%|▋         | 144/2295 [01:23<20:29,  1.75it/s, training_loss=2.714]\u001b[A\n",
      "Epoch 1:   6%|▋         | 145/2295 [01:23<20:30,  1.75it/s, training_loss=2.714]\u001b[A\n",
      "Epoch 1:   6%|▋         | 145/2295 [01:23<20:30,  1.75it/s, training_loss=2.794]\u001b[A\n",
      "Epoch 1:   6%|▋         | 146/2295 [01:23<20:29,  1.75it/s, training_loss=2.794]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▋         | 146/2295 [01:24<20:29,  1.75it/s, training_loss=2.855]\u001b[A\n",
      "Epoch 1:   6%|▋         | 147/2295 [01:24<20:27,  1.75it/s, training_loss=2.855]\u001b[A\n",
      "Epoch 1:   6%|▋         | 147/2295 [01:24<20:27,  1.75it/s, training_loss=2.912]\u001b[A\n",
      "Epoch 1:   6%|▋         | 148/2295 [01:24<20:26,  1.75it/s, training_loss=2.912]\u001b[A\n",
      "Epoch 1:   6%|▋         | 148/2295 [01:25<20:26,  1.75it/s, training_loss=2.698]\u001b[A\n",
      "Epoch 1:   6%|▋         | 149/2295 [01:25<20:24,  1.75it/s, training_loss=2.698]\u001b[A\n",
      "Epoch 1:   6%|▋         | 149/2295 [01:25<20:24,  1.75it/s, training_loss=2.803]\u001b[A\n",
      "Epoch 1:   7%|▋         | 150/2295 [01:25<20:23,  1.75it/s, training_loss=2.803]\u001b[A\n",
      "Epoch 1:   7%|▋         | 150/2295 [01:26<20:23,  1.75it/s, training_loss=2.874]\u001b[A\n",
      "Epoch 1:   7%|▋         | 151/2295 [01:26<20:23,  1.75it/s, training_loss=2.874]\u001b[A\n",
      "Epoch 1:   7%|▋         | 151/2295 [01:27<20:23,  1.75it/s, training_loss=2.818]\u001b[A\n",
      "Epoch 1:   7%|▋         | 152/2295 [01:27<20:24,  1.75it/s, training_loss=2.818]\u001b[A\n",
      "Epoch 1:   7%|▋         | 152/2295 [01:27<20:24,  1.75it/s, training_loss=2.756]\u001b[A\n",
      "Epoch 1:   7%|▋         | 153/2295 [01:27<20:23,  1.75it/s, training_loss=2.756]\u001b[A\n",
      "Epoch 1:   7%|▋         | 153/2295 [01:28<20:23,  1.75it/s, training_loss=2.755]\u001b[A\n",
      "Epoch 1:   7%|▋         | 154/2295 [01:28<20:22,  1.75it/s, training_loss=2.755]\u001b[A\n",
      "Epoch 1:   7%|▋         | 154/2295 [01:28<20:22,  1.75it/s, training_loss=2.718]\u001b[A\n",
      "Epoch 1:   7%|▋         | 155/2295 [01:28<20:21,  1.75it/s, training_loss=2.718]\u001b[A\n",
      "Epoch 1:   7%|▋         | 155/2295 [01:29<20:21,  1.75it/s, training_loss=2.726]\u001b[A\n",
      "Epoch 1:   7%|▋         | 156/2295 [01:29<20:21,  1.75it/s, training_loss=2.726]\u001b[A\n",
      "Epoch 1:   7%|▋         | 156/2295 [01:29<20:21,  1.75it/s, training_loss=2.775]\u001b[A\n",
      "Epoch 1:   7%|▋         | 157/2295 [01:29<20:20,  1.75it/s, training_loss=2.775]\u001b[A\n",
      "Epoch 1:   7%|▋         | 157/2295 [01:30<20:20,  1.75it/s, training_loss=2.734]\u001b[A\n",
      "Epoch 1:   7%|▋         | 158/2295 [01:30<20:20,  1.75it/s, training_loss=2.734]\u001b[A\n",
      "Epoch 1:   7%|▋         | 158/2295 [01:31<20:20,  1.75it/s, training_loss=2.783]\u001b[A\n",
      "Epoch 1:   7%|▋         | 159/2295 [01:31<20:19,  1.75it/s, training_loss=2.783]\u001b[A\n",
      "Epoch 1:   7%|▋         | 159/2295 [01:31<20:19,  1.75it/s, training_loss=2.751]\u001b[A\n",
      "Epoch 1:   7%|▋         | 160/2295 [01:31<20:17,  1.75it/s, training_loss=2.751]\u001b[A\n",
      "Epoch 1:   7%|▋         | 160/2295 [01:32<20:17,  1.75it/s, training_loss=2.704]\u001b[A\n",
      "Epoch 1:   7%|▋         | 161/2295 [01:32<20:18,  1.75it/s, training_loss=2.704]\u001b[A\n",
      "Epoch 1:   7%|▋         | 161/2295 [01:32<20:18,  1.75it/s, training_loss=2.734]\u001b[A\n",
      "Epoch 1:   7%|▋         | 162/2295 [01:32<20:19,  1.75it/s, training_loss=2.734]\u001b[A\n",
      "Epoch 1:   7%|▋         | 162/2295 [01:33<20:19,  1.75it/s, training_loss=2.728]\u001b[A\n",
      "Epoch 1:   7%|▋         | 163/2295 [01:33<20:18,  1.75it/s, training_loss=2.728]\u001b[A\n",
      "Epoch 1:   7%|▋         | 163/2295 [01:33<20:18,  1.75it/s, training_loss=2.776]\u001b[A\n",
      "Epoch 1:   7%|▋         | 164/2295 [01:33<20:18,  1.75it/s, training_loss=2.776]\u001b[A\n",
      "Epoch 1:   7%|▋         | 164/2295 [01:34<20:18,  1.75it/s, training_loss=2.728]\u001b[A\n",
      "Epoch 1:   7%|▋         | 165/2295 [01:34<20:16,  1.75it/s, training_loss=2.728]\u001b[A\n",
      "Epoch 1:   7%|▋         | 165/2295 [01:35<20:16,  1.75it/s, training_loss=2.794]\u001b[A\n",
      "Epoch 1:   7%|▋         | 166/2295 [01:35<20:15,  1.75it/s, training_loss=2.794]\u001b[A\n",
      "Epoch 1:   7%|▋         | 166/2295 [01:35<20:15,  1.75it/s, training_loss=2.743]\u001b[A\n",
      "Epoch 1:   7%|▋         | 167/2295 [01:35<20:13,  1.75it/s, training_loss=2.743]\u001b[A\n",
      "Epoch 1:   7%|▋         | 167/2295 [01:36<20:13,  1.75it/s, training_loss=2.724]\u001b[A\n",
      "Epoch 1:   7%|▋         | 168/2295 [01:36<20:12,  1.75it/s, training_loss=2.724]\u001b[A\n",
      "Epoch 1:   7%|▋         | 168/2295 [01:36<20:12,  1.75it/s, training_loss=2.767]\u001b[A\n",
      "Epoch 1:   7%|▋         | 169/2295 [01:36<20:12,  1.75it/s, training_loss=2.767]\u001b[A\n",
      "Epoch 1:   7%|▋         | 169/2295 [01:37<20:12,  1.75it/s, training_loss=2.741]\u001b[A\n",
      "Epoch 1:   7%|▋         | 170/2295 [01:37<20:10,  1.75it/s, training_loss=2.741]\u001b[A\n",
      "Epoch 1:   7%|▋         | 170/2295 [01:37<20:10,  1.75it/s, training_loss=2.647]\u001b[A\n",
      "Epoch 1:   7%|▋         | 171/2295 [01:37<20:10,  1.75it/s, training_loss=2.647]\u001b[A\n",
      "Epoch 1:   7%|▋         | 171/2295 [01:38<20:10,  1.75it/s, training_loss=2.649]\u001b[A\n",
      "Epoch 1:   7%|▋         | 172/2295 [01:38<20:11,  1.75it/s, training_loss=2.649]\u001b[A\n",
      "Epoch 1:   7%|▋         | 172/2295 [01:39<20:11,  1.75it/s, training_loss=2.671]\u001b[A\n",
      "Epoch 1:   8%|▊         | 173/2295 [01:39<20:11,  1.75it/s, training_loss=2.671]\u001b[A\n",
      "Epoch 1:   8%|▊         | 173/2295 [01:39<20:11,  1.75it/s, training_loss=2.642]\u001b[A\n",
      "Epoch 1:   8%|▊         | 174/2295 [01:39<20:11,  1.75it/s, training_loss=2.642]\u001b[A\n",
      "Epoch 1:   8%|▊         | 174/2295 [01:40<20:11,  1.75it/s, training_loss=2.603]\u001b[A\n",
      "Epoch 1:   8%|▊         | 175/2295 [01:40<20:10,  1.75it/s, training_loss=2.603]\u001b[A\n",
      "Epoch 1:   8%|▊         | 175/2295 [01:40<20:10,  1.75it/s, training_loss=2.535]\u001b[A\n",
      "Epoch 1:   8%|▊         | 176/2295 [01:40<20:09,  1.75it/s, training_loss=2.535]\u001b[A\n",
      "Epoch 1:   8%|▊         | 176/2295 [01:41<20:09,  1.75it/s, training_loss=2.660]\u001b[A\n",
      "Epoch 1:   8%|▊         | 177/2295 [01:41<20:09,  1.75it/s, training_loss=2.660]\u001b[A\n",
      "Epoch 1:   8%|▊         | 177/2295 [01:41<20:09,  1.75it/s, training_loss=2.681]\u001b[A\n",
      "Epoch 1:   8%|▊         | 178/2295 [01:41<20:08,  1.75it/s, training_loss=2.681]\u001b[A\n",
      "Epoch 1:   8%|▊         | 178/2295 [01:42<20:08,  1.75it/s, training_loss=2.634]\u001b[A\n",
      "Epoch 1:   8%|▊         | 179/2295 [01:42<20:07,  1.75it/s, training_loss=2.634]\u001b[A\n",
      "Epoch 1:   8%|▊         | 179/2295 [01:43<20:07,  1.75it/s, training_loss=2.701]\u001b[A\n",
      "Epoch 1:   8%|▊         | 180/2295 [01:43<20:06,  1.75it/s, training_loss=2.701]\u001b[A\n",
      "Epoch 1:   8%|▊         | 180/2295 [01:43<20:06,  1.75it/s, training_loss=2.659]\u001b[A\n",
      "Epoch 1:   8%|▊         | 181/2295 [01:43<20:04,  1.76it/s, training_loss=2.659]\u001b[A\n",
      "Epoch 1:   8%|▊         | 181/2295 [01:44<20:04,  1.76it/s, training_loss=2.715]\u001b[A\n",
      "Epoch 1:   8%|▊         | 182/2295 [01:44<20:05,  1.75it/s, training_loss=2.715]\u001b[A\n",
      "Epoch 1:   8%|▊         | 182/2295 [01:44<20:05,  1.75it/s, training_loss=2.684]\u001b[A\n",
      "Epoch 1:   8%|▊         | 183/2295 [01:44<20:07,  1.75it/s, training_loss=2.684]\u001b[A\n",
      "Epoch 1:   8%|▊         | 183/2295 [01:45<20:07,  1.75it/s, training_loss=2.578]\u001b[A\n",
      "Epoch 1:   8%|▊         | 184/2295 [01:45<20:06,  1.75it/s, training_loss=2.578]\u001b[A\n",
      "Epoch 1:   8%|▊         | 184/2295 [01:45<20:06,  1.75it/s, training_loss=2.763]\u001b[A\n",
      "Epoch 1:   8%|▊         | 185/2295 [01:45<20:08,  1.75it/s, training_loss=2.763]\u001b[A\n",
      "Epoch 1:   8%|▊         | 185/2295 [01:46<20:08,  1.75it/s, training_loss=2.740]\u001b[A\n",
      "Epoch 1:   8%|▊         | 186/2295 [01:46<20:07,  1.75it/s, training_loss=2.740]\u001b[A\n",
      "Epoch 1:   8%|▊         | 186/2295 [01:47<20:07,  1.75it/s, training_loss=2.672]\u001b[A\n",
      "Epoch 1:   8%|▊         | 187/2295 [01:47<20:06,  1.75it/s, training_loss=2.672]\u001b[A\n",
      "Epoch 1:   8%|▊         | 187/2295 [01:47<20:06,  1.75it/s, training_loss=2.740]\u001b[A\n",
      "Epoch 1:   8%|▊         | 188/2295 [01:47<20:04,  1.75it/s, training_loss=2.740]\u001b[A\n",
      "Epoch 1:   8%|▊         | 188/2295 [01:48<20:04,  1.75it/s, training_loss=2.656]\u001b[A\n",
      "Epoch 1:   8%|▊         | 189/2295 [01:48<20:02,  1.75it/s, training_loss=2.656]\u001b[A\n",
      "Epoch 1:   8%|▊         | 189/2295 [01:48<20:02,  1.75it/s, training_loss=2.712]\u001b[A\n",
      "Epoch 1:   8%|▊         | 190/2295 [01:48<20:01,  1.75it/s, training_loss=2.712]\u001b[A\n",
      "Epoch 1:   8%|▊         | 190/2295 [01:49<20:01,  1.75it/s, training_loss=2.779]\u001b[A\n",
      "Epoch 1:   8%|▊         | 191/2295 [01:49<20:02,  1.75it/s, training_loss=2.779]\u001b[A\n",
      "Epoch 1:   8%|▊         | 191/2295 [01:49<20:02,  1.75it/s, training_loss=2.635]\u001b[A\n",
      "Epoch 1:   8%|▊         | 192/2295 [01:49<20:01,  1.75it/s, training_loss=2.635]\u001b[A\n",
      "Epoch 1:   8%|▊         | 192/2295 [01:50<20:01,  1.75it/s, training_loss=2.799]\u001b[A\n",
      "Epoch 1:   8%|▊         | 193/2295 [01:50<20:02,  1.75it/s, training_loss=2.799]\u001b[A\n",
      "Epoch 1:   8%|▊         | 193/2295 [01:51<20:02,  1.75it/s, training_loss=2.722]\u001b[A\n",
      "Epoch 1:   8%|▊         | 194/2295 [01:51<20:01,  1.75it/s, training_loss=2.722]\u001b[A\n",
      "Epoch 1:   8%|▊         | 194/2295 [01:51<20:01,  1.75it/s, training_loss=2.679]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 195/2295 [01:51<20:00,  1.75it/s, training_loss=2.679]\u001b[A\n",
      "Epoch 1:   8%|▊         | 195/2295 [01:52<20:00,  1.75it/s, training_loss=2.693]\u001b[A\n",
      "Epoch 1:   9%|▊         | 196/2295 [01:52<19:59,  1.75it/s, training_loss=2.693]\u001b[A\n",
      "Epoch 1:   9%|▊         | 196/2295 [01:52<19:59,  1.75it/s, training_loss=2.616]\u001b[A\n",
      "Epoch 1:   9%|▊         | 197/2295 [01:52<19:59,  1.75it/s, training_loss=2.616]\u001b[A\n",
      "Epoch 1:   9%|▊         | 197/2295 [01:53<19:59,  1.75it/s, training_loss=2.742]\u001b[A\n",
      "Epoch 1:   9%|▊         | 198/2295 [01:53<19:59,  1.75it/s, training_loss=2.742]\u001b[A\n",
      "Epoch 1:   9%|▊         | 198/2295 [01:53<19:59,  1.75it/s, training_loss=2.883]\u001b[A\n",
      "Epoch 1:   9%|▊         | 199/2295 [01:53<19:58,  1.75it/s, training_loss=2.883]\u001b[A\n",
      "Epoch 1:   9%|▊         | 199/2295 [01:54<19:58,  1.75it/s, training_loss=2.548]\u001b[A\n",
      "Epoch 1:   9%|▊         | 200/2295 [01:54<19:57,  1.75it/s, training_loss=2.548]\u001b[A\n",
      "Epoch 1:   9%|▊         | 200/2295 [01:55<19:57,  1.75it/s, training_loss=2.752]\u001b[A\n",
      "Epoch 1:   9%|▉         | 201/2295 [01:55<19:56,  1.75it/s, training_loss=2.752]\u001b[A\n",
      "Epoch 1:   9%|▉         | 201/2295 [01:55<19:56,  1.75it/s, training_loss=2.692]\u001b[A\n",
      "Epoch 1:   9%|▉         | 202/2295 [01:55<19:56,  1.75it/s, training_loss=2.692]\u001b[A\n",
      "Epoch 1:   9%|▉         | 202/2295 [01:56<19:56,  1.75it/s, training_loss=2.662]\u001b[A\n",
      "Epoch 1:   9%|▉         | 203/2295 [01:56<19:54,  1.75it/s, training_loss=2.662]\u001b[A\n",
      "Epoch 1:   9%|▉         | 203/2295 [01:56<19:54,  1.75it/s, training_loss=2.655]\u001b[A\n",
      "Epoch 1:   9%|▉         | 204/2295 [01:56<19:54,  1.75it/s, training_loss=2.655]\u001b[A\n",
      "Epoch 1:   9%|▉         | 204/2295 [01:57<19:54,  1.75it/s, training_loss=2.644]\u001b[A\n",
      "Epoch 1:   9%|▉         | 205/2295 [01:57<19:53,  1.75it/s, training_loss=2.644]\u001b[A\n",
      "Epoch 1:   9%|▉         | 205/2295 [01:57<19:53,  1.75it/s, training_loss=2.729]\u001b[A\n",
      "Epoch 1:   9%|▉         | 206/2295 [01:57<19:53,  1.75it/s, training_loss=2.729]\u001b[A\n",
      "Epoch 1:   9%|▉         | 206/2295 [01:58<19:53,  1.75it/s, training_loss=2.718]\u001b[A\n",
      "Epoch 1:   9%|▉         | 207/2295 [01:58<19:52,  1.75it/s, training_loss=2.718]\u001b[A\n",
      "Epoch 1:   9%|▉         | 207/2295 [01:59<19:52,  1.75it/s, training_loss=2.648]\u001b[A\n",
      "Epoch 1:   9%|▉         | 208/2295 [01:59<19:52,  1.75it/s, training_loss=2.648]\u001b[A\n",
      "Epoch 1:   9%|▉         | 208/2295 [01:59<19:52,  1.75it/s, training_loss=2.612]\u001b[A\n",
      "Epoch 1:   9%|▉         | 209/2295 [01:59<19:51,  1.75it/s, training_loss=2.612]\u001b[A\n",
      "Epoch 1:   9%|▉         | 209/2295 [02:00<19:51,  1.75it/s, training_loss=2.652]\u001b[A\n",
      "Epoch 1:   9%|▉         | 210/2295 [02:00<19:52,  1.75it/s, training_loss=2.652]\u001b[A\n",
      "Epoch 1:   9%|▉         | 210/2295 [02:00<19:52,  1.75it/s, training_loss=2.705]\u001b[A\n",
      "Epoch 1:   9%|▉         | 211/2295 [02:00<19:49,  1.75it/s, training_loss=2.705]\u001b[A\n",
      "Epoch 1:   9%|▉         | 211/2295 [02:01<19:49,  1.75it/s, training_loss=2.714]\u001b[A\n",
      "Epoch 1:   9%|▉         | 212/2295 [02:01<19:49,  1.75it/s, training_loss=2.714]\u001b[A\n",
      "Epoch 1:   9%|▉         | 212/2295 [02:01<19:49,  1.75it/s, training_loss=2.672]\u001b[A\n",
      "Epoch 1:   9%|▉         | 213/2295 [02:01<19:49,  1.75it/s, training_loss=2.672]\u001b[A\n",
      "Epoch 1:   9%|▉         | 213/2295 [02:02<19:49,  1.75it/s, training_loss=2.787]\u001b[A\n",
      "Epoch 1:   9%|▉         | 214/2295 [02:02<19:51,  1.75it/s, training_loss=2.787]\u001b[A\n",
      "Epoch 1:   9%|▉         | 214/2295 [02:03<19:51,  1.75it/s, training_loss=2.596]\u001b[A\n",
      "Epoch 1:   9%|▉         | 215/2295 [02:03<19:48,  1.75it/s, training_loss=2.596]\u001b[A\n",
      "Epoch 1:   9%|▉         | 215/2295 [02:03<19:48,  1.75it/s, training_loss=2.624]\u001b[A\n",
      "Epoch 1:   9%|▉         | 216/2295 [02:03<19:48,  1.75it/s, training_loss=2.624]\u001b[A\n",
      "Epoch 1:   9%|▉         | 216/2295 [02:04<19:48,  1.75it/s, training_loss=2.671]\u001b[A\n",
      "Epoch 1:   9%|▉         | 217/2295 [02:04<19:45,  1.75it/s, training_loss=2.671]\u001b[A\n",
      "Epoch 1:   9%|▉         | 217/2295 [02:04<19:45,  1.75it/s, training_loss=2.760]\u001b[A\n",
      "Epoch 1:   9%|▉         | 218/2295 [02:04<19:45,  1.75it/s, training_loss=2.760]\u001b[A\n",
      "Epoch 1:   9%|▉         | 218/2295 [02:05<19:45,  1.75it/s, training_loss=2.677]\u001b[A\n",
      "Epoch 1:  10%|▉         | 219/2295 [02:05<19:45,  1.75it/s, training_loss=2.677]\u001b[A\n",
      "Epoch 1:  10%|▉         | 219/2295 [02:05<19:45,  1.75it/s, training_loss=2.578]\u001b[A\n",
      "Epoch 1:  10%|▉         | 220/2295 [02:05<19:45,  1.75it/s, training_loss=2.578]\u001b[A\n",
      "Epoch 1:  10%|▉         | 220/2295 [02:06<19:45,  1.75it/s, training_loss=2.759]\u001b[A\n",
      "Epoch 1:  10%|▉         | 221/2295 [02:06<19:44,  1.75it/s, training_loss=2.759]\u001b[A\n",
      "Epoch 1:  10%|▉         | 221/2295 [02:07<19:44,  1.75it/s, training_loss=2.704]\u001b[A\n",
      "Epoch 1:  10%|▉         | 222/2295 [02:07<19:43,  1.75it/s, training_loss=2.704]\u001b[A\n",
      "Epoch 1:  10%|▉         | 222/2295 [02:07<19:43,  1.75it/s, training_loss=2.672]\u001b[A\n",
      "Epoch 1:  10%|▉         | 223/2295 [02:07<19:45,  1.75it/s, training_loss=2.672]\u001b[A\n",
      "Epoch 1:  10%|▉         | 223/2295 [02:08<19:45,  1.75it/s, training_loss=2.797]\u001b[A\n",
      "Epoch 1:  10%|▉         | 224/2295 [02:08<19:43,  1.75it/s, training_loss=2.797]\u001b[A\n",
      "Epoch 1:  10%|▉         | 224/2295 [02:08<19:43,  1.75it/s, training_loss=2.697]\u001b[A\n",
      "Epoch 1:  10%|▉         | 225/2295 [02:08<19:44,  1.75it/s, training_loss=2.697]\u001b[A\n",
      "Epoch 1:  10%|▉         | 225/2295 [02:09<19:44,  1.75it/s, training_loss=2.702]\u001b[A\n",
      "Epoch 1:  10%|▉         | 226/2295 [02:09<19:43,  1.75it/s, training_loss=2.702]\u001b[A\n",
      "Epoch 1:  10%|▉         | 226/2295 [02:09<19:43,  1.75it/s, training_loss=2.660]\u001b[A\n",
      "Epoch 1:  10%|▉         | 227/2295 [02:09<19:42,  1.75it/s, training_loss=2.660]\u001b[A\n",
      "Epoch 1:  10%|▉         | 227/2295 [02:10<19:42,  1.75it/s, training_loss=2.730]\u001b[A\n",
      "Epoch 1:  10%|▉         | 228/2295 [02:10<19:42,  1.75it/s, training_loss=2.730]\u001b[A\n",
      "Epoch 1:  10%|▉         | 228/2295 [02:11<19:42,  1.75it/s, training_loss=2.670]\u001b[A\n",
      "Epoch 1:  10%|▉         | 229/2295 [02:11<19:42,  1.75it/s, training_loss=2.670]\u001b[A\n",
      "Epoch 1:  10%|▉         | 229/2295 [02:11<19:42,  1.75it/s, training_loss=2.652]\u001b[A\n",
      "Epoch 1:  10%|█         | 230/2295 [02:11<19:42,  1.75it/s, training_loss=2.652]\u001b[A\n",
      "Epoch 1:  10%|█         | 230/2295 [02:12<19:42,  1.75it/s, training_loss=2.604]\u001b[A\n",
      "Epoch 1:  10%|█         | 231/2295 [02:12<19:42,  1.75it/s, training_loss=2.604]\u001b[A\n",
      "Epoch 1:  10%|█         | 231/2295 [02:12<19:42,  1.75it/s, training_loss=2.662]\u001b[A\n",
      "Epoch 1:  10%|█         | 232/2295 [02:12<19:39,  1.75it/s, training_loss=2.662]\u001b[A\n",
      "Epoch 1:  10%|█         | 232/2295 [02:13<19:39,  1.75it/s, training_loss=2.678]\u001b[A\n",
      "Epoch 1:  10%|█         | 233/2295 [02:13<19:37,  1.75it/s, training_loss=2.678]\u001b[A\n",
      "Epoch 1:  10%|█         | 233/2295 [02:13<19:37,  1.75it/s, training_loss=2.660]\u001b[A\n",
      "Epoch 1:  10%|█         | 234/2295 [02:13<19:37,  1.75it/s, training_loss=2.660]\u001b[A\n",
      "Epoch 1:  10%|█         | 234/2295 [02:14<19:37,  1.75it/s, training_loss=2.626]\u001b[A\n",
      "Epoch 1:  10%|█         | 235/2295 [02:14<19:36,  1.75it/s, training_loss=2.626]\u001b[A\n",
      "Epoch 1:  10%|█         | 235/2295 [02:15<19:36,  1.75it/s, training_loss=2.694]\u001b[A\n",
      "Epoch 1:  10%|█         | 236/2295 [02:15<19:34,  1.75it/s, training_loss=2.694]\u001b[A\n",
      "Epoch 1:  10%|█         | 236/2295 [02:15<19:34,  1.75it/s, training_loss=2.500]\u001b[A\n",
      "Epoch 1:  10%|█         | 237/2295 [02:15<19:35,  1.75it/s, training_loss=2.500]\u001b[A\n",
      "Epoch 1:  10%|█         | 237/2295 [02:16<19:35,  1.75it/s, training_loss=2.716]\u001b[A\n",
      "Epoch 1:  10%|█         | 238/2295 [02:16<19:34,  1.75it/s, training_loss=2.716]\u001b[A\n",
      "Epoch 1:  10%|█         | 238/2295 [02:16<19:34,  1.75it/s, training_loss=2.755]\u001b[A\n",
      "Epoch 1:  10%|█         | 239/2295 [02:16<19:34,  1.75it/s, training_loss=2.755]\u001b[A\n",
      "Epoch 1:  10%|█         | 239/2295 [02:17<19:34,  1.75it/s, training_loss=2.651]\u001b[A\n",
      "Epoch 1:  10%|█         | 240/2295 [02:17<19:35,  1.75it/s, training_loss=2.651]\u001b[A\n",
      "Epoch 1:  10%|█         | 240/2295 [02:17<19:35,  1.75it/s, training_loss=2.618]\u001b[A\n",
      "Epoch 1:  11%|█         | 241/2295 [02:17<19:34,  1.75it/s, training_loss=2.618]\u001b[A\n",
      "Epoch 1:  11%|█         | 241/2295 [02:18<19:34,  1.75it/s, training_loss=2.715]\u001b[A\n",
      "Epoch 1:  11%|█         | 242/2295 [02:18<19:34,  1.75it/s, training_loss=2.715]\u001b[A\n",
      "Epoch 1:  11%|█         | 242/2295 [02:19<19:34,  1.75it/s, training_loss=2.612]\u001b[A\n",
      "Epoch 1:  11%|█         | 243/2295 [02:19<19:35,  1.75it/s, training_loss=2.612]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█         | 243/2295 [02:19<19:35,  1.75it/s, training_loss=2.661]\u001b[A\n",
      "Epoch 1:  11%|█         | 244/2295 [02:19<19:32,  1.75it/s, training_loss=2.661]\u001b[A\n",
      "Epoch 1:  11%|█         | 244/2295 [02:20<19:32,  1.75it/s, training_loss=2.632]\u001b[A\n",
      "Epoch 1:  11%|█         | 245/2295 [02:20<19:31,  1.75it/s, training_loss=2.632]\u001b[A\n",
      "Epoch 1:  11%|█         | 245/2295 [02:20<19:31,  1.75it/s, training_loss=2.618]\u001b[A\n",
      "Epoch 1:  11%|█         | 246/2295 [02:20<19:30,  1.75it/s, training_loss=2.618]\u001b[A\n",
      "Epoch 1:  11%|█         | 246/2295 [02:21<19:30,  1.75it/s, training_loss=2.595]\u001b[A\n",
      "Epoch 1:  11%|█         | 247/2295 [02:21<19:29,  1.75it/s, training_loss=2.595]\u001b[A\n",
      "Epoch 1:  11%|█         | 247/2295 [02:21<19:29,  1.75it/s, training_loss=2.699]\u001b[A\n",
      "Epoch 1:  11%|█         | 248/2295 [02:21<19:30,  1.75it/s, training_loss=2.699]\u001b[A\n",
      "Epoch 1:  11%|█         | 248/2295 [02:22<19:30,  1.75it/s, training_loss=2.753]\u001b[A\n",
      "Epoch 1:  11%|█         | 249/2295 [02:22<19:30,  1.75it/s, training_loss=2.753]\u001b[A\n",
      "Epoch 1:  11%|█         | 249/2295 [02:23<19:30,  1.75it/s, training_loss=2.688]\u001b[A\n",
      "Epoch 1:  11%|█         | 250/2295 [02:23<19:28,  1.75it/s, training_loss=2.688]\u001b[A\n",
      "Epoch 1:  11%|█         | 250/2295 [02:23<19:28,  1.75it/s, training_loss=2.777]\u001b[A\n",
      "Epoch 1:  11%|█         | 251/2295 [02:23<19:29,  1.75it/s, training_loss=2.777]\u001b[A\n",
      "Epoch 1:  11%|█         | 251/2295 [02:24<19:29,  1.75it/s, training_loss=2.781]\u001b[A\n",
      "Epoch 1:  11%|█         | 252/2295 [02:24<19:27,  1.75it/s, training_loss=2.781]\u001b[A\n",
      "Epoch 1:  11%|█         | 252/2295 [02:24<19:27,  1.75it/s, training_loss=2.454]\u001b[A\n",
      "Epoch 1:  11%|█         | 253/2295 [02:24<19:27,  1.75it/s, training_loss=2.454]\u001b[A\n",
      "Epoch 1:  11%|█         | 253/2295 [02:25<19:27,  1.75it/s, training_loss=2.603]\u001b[A\n",
      "Epoch 1:  11%|█         | 254/2295 [02:25<19:27,  1.75it/s, training_loss=2.603]\u001b[A\n",
      "Epoch 1:  11%|█         | 254/2295 [02:25<19:27,  1.75it/s, training_loss=2.508]\u001b[A\n",
      "Epoch 1:  11%|█         | 255/2295 [02:25<19:26,  1.75it/s, training_loss=2.508]\u001b[A\n",
      "Epoch 1:  11%|█         | 255/2295 [02:26<19:26,  1.75it/s, training_loss=2.617]\u001b[A\n",
      "Epoch 1:  11%|█         | 256/2295 [02:26<19:28,  1.75it/s, training_loss=2.617]\u001b[A\n",
      "Epoch 1:  11%|█         | 256/2295 [02:27<19:28,  1.75it/s, training_loss=2.546]\u001b[A\n",
      "Epoch 1:  11%|█         | 257/2295 [02:27<19:28,  1.74it/s, training_loss=2.546]\u001b[A\n",
      "Epoch 1:  11%|█         | 257/2295 [02:27<19:28,  1.74it/s, training_loss=2.584]\u001b[A\n",
      "Epoch 1:  11%|█         | 258/2295 [02:27<19:26,  1.75it/s, training_loss=2.584]\u001b[A\n",
      "Epoch 1:  11%|█         | 258/2295 [02:28<19:26,  1.75it/s, training_loss=2.556]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 259/2295 [02:28<19:25,  1.75it/s, training_loss=2.556]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 259/2295 [02:28<19:25,  1.75it/s, training_loss=2.563]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 260/2295 [02:28<19:24,  1.75it/s, training_loss=2.563]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 260/2295 [02:29<19:24,  1.75it/s, training_loss=2.688]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 261/2295 [02:29<19:23,  1.75it/s, training_loss=2.688]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 261/2295 [02:29<19:23,  1.75it/s, training_loss=2.656]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 262/2295 [02:29<19:23,  1.75it/s, training_loss=2.656]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 262/2295 [02:30<19:23,  1.75it/s, training_loss=2.629]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 263/2295 [02:30<19:22,  1.75it/s, training_loss=2.629]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 263/2295 [02:31<19:22,  1.75it/s, training_loss=2.599]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 264/2295 [02:31<19:20,  1.75it/s, training_loss=2.599]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 264/2295 [02:31<19:20,  1.75it/s, training_loss=2.587]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 265/2295 [02:31<19:21,  1.75it/s, training_loss=2.587]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 265/2295 [02:32<19:21,  1.75it/s, training_loss=2.650]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 266/2295 [02:32<19:22,  1.75it/s, training_loss=2.650]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 266/2295 [02:32<19:22,  1.75it/s, training_loss=2.741]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 267/2295 [02:32<19:20,  1.75it/s, training_loss=2.741]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 267/2295 [02:33<19:20,  1.75it/s, training_loss=2.600]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 268/2295 [02:33<19:22,  1.74it/s, training_loss=2.600]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 268/2295 [02:33<19:22,  1.74it/s, training_loss=2.544]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 269/2295 [02:33<19:21,  1.74it/s, training_loss=2.544]\u001b[A"
     ]
    }
   ],
   "source": [
    "val_losses,training_losses,t5_model=train_model(t5_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "lq3iHnbiI8yb",
    "outputId": "396bc55c-6719-4865-b7db-0d34bf15c0bb"
   },
   "outputs": [],
   "source": [
    "\n",
    "n_epochs=len(training_losses)\n",
    "\n",
    "epochs_arr=np.arange(start=1,stop=n_epochs+1,step=1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epochs_arr,val_losses,label='Validation Loss')\n",
    "plt.plot(epochs_arr,training_losses,label='Training Loss')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "gX_40sFWKIm8"
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4t-MOhnsKq-o"
   },
   "outputs": [],
   "source": [
    "def getPredictionsTopK(inputs,model,device):\n",
    "      sample_outputs = model.generate(\n",
    "        input_ids.to(device),\n",
    "        do_sample=True, \n",
    "        max_length=1800, \n",
    "        top_k=900, \n",
    "        top_p=0.95, \n",
    "        num_return_sequences=3)\n",
    "    # outputs = model.generate(input_ids)\n",
    "      sequences=[]\n",
    "      for i in range(sample_outputs.shape[0]):\n",
    "        sequences.append(tokenizer.decode(sample_outputs[i], skip_special_tokens=True))\n",
    "      return sequences\n",
    "\n",
    "def getPredictionsGreedy(inputs,model,device):\n",
    "      greedy_output = model.generate(input_ids.to(device), max_length=1800)\n",
    "      sequences=[]\n",
    "      for i in range(greedy_output.shape[0]):\n",
    "        sequences.append(tokenizer.decode(greedy_output[i], skip_special_tokens=True))\n",
    "      return sequences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yf0_fIzz9ZY0"
   },
   "outputs": [],
   "source": [
    "def getPredictedTexts(dataloader_test,genAlgo,model,device):\n",
    "    predictions=[]\n",
    "    allExpectedprogs=[]\n",
    "    idx=0\n",
    "    for ip,eop,estr in dataloader_test:\n",
    "        print(f\"iter{idx} of {len(dataloader_test)}\")\n",
    "        prediction=genAlgo(ip,model,device)\n",
    "        predictions=predictions+prediction\n",
    "        expected=[x for x in estr]\n",
    "        allExpectedprogs=allExpectedprogs+expected\n",
    "        idx+=1\n",
    "    return allExpectedprogs,predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJPyaWnDBcbm",
    "outputId": "9c27391f-78f2-417c-db58-154bdb3c7ea7"
   },
   "outputs": [],
   "source": [
    "allExpectedprogsGreedy,predictionsGreedy=getPredictedTexts(dataloader_test,getPredictionsGreedy,t5_model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2G5uUfgrDarO"
   },
   "outputs": [],
   "source": [
    "predictiondf_t5 = pd.DataFrame(list(zip(allExpectedprogsGreedy, predictionsGreedy)), columns =['Expected', 'predictions']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfXy3j8tEpF9"
   },
   "outputs": [],
   "source": [
    "predictiondf_t5.to_json('./predictions_codet5.jsonl',orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtu9P5HkIlk9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cmj3IqJdIl_E",
    "outputId": "4d3e8e09-f655-4400-aaf7-2d29224e687f"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4o-l3kPLIQhe"
   },
   "outputs": [],
   "source": [
    "torch.save(t5_model.state_dict(), f'Models/CodeT5_ft_final.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CodeT5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "044cbfb13fe243ef8fdc99691bc9df9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04e02a2cb7d146f79089f204ee834620": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2820c54debe46e686aeb2326f5f5225",
      "placeholder": "​",
      "style": "IPY_MODEL_350ad93ce7de4b338c8e2055fb166155",
      "value": " 12.2k/12.2k [00:00&lt;00:00, 533kB/s]"
     }
    },
    "073c2abbe9564a529704d8d2c4c1e21a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fac156490a94fc6b2656312bb35c921": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33d38ade070b4e1b9baf5683464147f7",
      "placeholder": "​",
      "style": "IPY_MODEL_7d443f008c12491d81d3e2d6f6f62c46",
      "value": "Downloading: 100%"
     }
    },
    "107c9db3eb394897aa35eeb73aca58a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24886985211f40c985a8366c26ba59ae",
      "placeholder": "​",
      "style": "IPY_MODEL_b6fb9a445be74b2884194f1c059ea953",
      "value": "Downloading: 100%"
     }
    },
    "177c7b72f5494a77a4e99f784b04a140": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78138fd78fc147eeb63d99c19c107379",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_69b704498b40482b9d5a558267095431",
      "value": 2
     }
    },
    "18a7e10f6da849ad9c95c720dcabd5e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_921bcaed79134ad98ba87bd9a6d3a0a2",
      "max": 1477,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a30e5173a933485bbaec0950b8144322",
      "value": 1477
     }
    },
    "18cd4d70e52a490ca646e37935f22b09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e6db17f8a5ea4231be6c63952abc9be0",
       "IPY_MODEL_18a7e10f6da849ad9c95c720dcabd5e7",
       "IPY_MODEL_3c965a35d26842db9fcc8273b9e53d1f"
      ],
      "layout": "IPY_MODEL_f301256384f44e558759a3e478d4dd4f"
     }
    },
    "19056d6013a140668aca04ee96d20aa2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc3d15ead0ec4452b1ad06e029f66fa4",
      "placeholder": "​",
      "style": "IPY_MODEL_bccf935bc9334a5793a681de4863654e",
      "value": "Downloading: 100%"
     }
    },
    "1dd805a73f9b46949a7cc0cb8152d248": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "222def9d04434f529063233f364fa384": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58e4477f271f4ea7a3dece11b61dc982",
      "max": 12512,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a67948a75e8c4753bb3be7f50cb69b2c",
      "value": 12512
     }
    },
    "24886985211f40c985a8366c26ba59ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "249578c83d2840a19197ab99c0778379": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2e0c03ae0eb47f5b2f90861e4fa67e6",
      "placeholder": "​",
      "style": "IPY_MODEL_c0e62fd3d424468ebd4f5b5415710b5d",
      "value": "Downloading: 100%"
     }
    },
    "28ee415f653f4bca892b917cc4d59516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2bea6b92eafb4b299164996975716a4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33d38ade070b4e1b9baf5683464147f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "350ad93ce7de4b338c8e2055fb166155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35f5205d66fb430f9c5456bbf12026f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c49b3523d05451d802d5b685534e393": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d63664f79e0646d1926203d08487237a",
      "max": 294364,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf8b4c128350479f9823d3f3243752f7",
      "value": 294364
     }
    },
    "3c965a35d26842db9fcc8273b9e53d1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7c41db284d746b98f3f002bfc51cb1d",
      "placeholder": "​",
      "style": "IPY_MODEL_073c2abbe9564a529704d8d2c4c1e21a",
      "value": " 1.44k/1.44k [00:00&lt;00:00, 59.4kB/s]"
     }
    },
    "3f9fdc363f934e6bb74be7f574c23de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_19056d6013a140668aca04ee96d20aa2",
       "IPY_MODEL_3c49b3523d05451d802d5b685534e393",
       "IPY_MODEL_79bec1b343964a00846e392859774a1d"
      ],
      "layout": "IPY_MODEL_e4276c9f591247589623b5ff20449496"
     }
    },
    "44e525ce3e704386b61582ba7996bae1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45a3a944205e4b439834ba591c73e6b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "480d94da0fb74e2b99c876a752a1b308": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "483fa124b73641ab90e962a8f07d9edc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f98f267828b4c4aacc73b06e95bf737",
      "placeholder": "​",
      "style": "IPY_MODEL_894968a3a1b4400b890bedb0a478dde0",
      "value": " 231M/231M [00:04&lt;00:00, 67.1MB/s]"
     }
    },
    "4bbdb3bf20ae4b0bbcfbecaafdee08fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9226a0ae61fe4139b1dfcc7b4f3c6048",
       "IPY_MODEL_5a7e1836247642199ab3e8879a571df3",
       "IPY_MODEL_7906838c5de243db9442473d2fcbd810"
      ],
      "layout": "IPY_MODEL_5151ce33e66a40268675e60adc68a144"
     }
    },
    "4bfd289d8eab426c8ab66bba4b470041": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5151ce33e66a40268675e60adc68a144": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "535a2e7f9054416ea6a7aa1e7afcafe1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "546f6b6cc5a14708bcf05cfd08fc6351": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b3a6015983b459ea85ee1a49ed0d13a",
      "placeholder": "​",
      "style": "IPY_MODEL_648ad9ff35274fbeaf78df5c3e76fd68",
      "value": " 687k/687k [00:00&lt;00:00, 796kB/s]"
     }
    },
    "58ad5efc745d4716b753ec30345a24fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_107c9db3eb394897aa35eeb73aca58a7",
       "IPY_MODEL_a15d541c346441d1990f63b46f3d685a",
       "IPY_MODEL_546f6b6cc5a14708bcf05cfd08fc6351"
      ],
      "layout": "IPY_MODEL_44e525ce3e704386b61582ba7996bae1"
     }
    },
    "58e4477f271f4ea7a3dece11b61dc982": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a7e1836247642199ab3e8879a571df3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aed68e0e0f8a4185956e6d277058c17b",
      "max": 1566,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d46e63c37e7a46eabaae89892be902d8",
      "value": 1566
     }
    },
    "5bf65953abef4f32a9f9b6fc5b3690ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "648ad9ff35274fbeaf78df5c3e76fd68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69b704498b40482b9d5a558267095431": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6cf5481a6d6b40c2b7b3407dd3986921": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f98f267828b4c4aacc73b06e95bf737": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78138fd78fc147eeb63d99c19c107379": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7906838c5de243db9442473d2fcbd810": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_044cbfb13fe243ef8fdc99691bc9df9f",
      "placeholder": "​",
      "style": "IPY_MODEL_480d94da0fb74e2b99c876a752a1b308",
      "value": " 1.53k/1.53k [00:00&lt;00:00, 60.6kB/s]"
     }
    },
    "79bec1b343964a00846e392859774a1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb24ad0a76de4e4ca3649809d40437b7",
      "placeholder": "​",
      "style": "IPY_MODEL_535a2e7f9054416ea6a7aa1e7afcafe1",
      "value": " 287k/287k [00:00&lt;00:00, 791kB/s]"
     }
    },
    "7d443f008c12491d81d3e2d6f6f62c46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "894968a3a1b4400b890bedb0a478dde0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b3a6015983b459ea85ee1a49ed0d13a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90701ff27c864ffbabfffa91c3b3c37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dd805a73f9b46949a7cc0cb8152d248",
      "max": 242026427,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8afb472ba944bc4bb94192466d9bbc5",
      "value": 242026427
     }
    },
    "90853cbd095c456b8f33f8efd0ef07ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90ae1f11ae42495c9ee6bdec12a2e6ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe47a6270e624095a23cdf87ceb48b27",
      "placeholder": "​",
      "style": "IPY_MODEL_5bf65953abef4f32a9f9b6fc5b3690ac",
      "value": " 2.00/2.00 [00:00&lt;00:00, 73.9B/s]"
     }
    },
    "921bcaed79134ad98ba87bd9a6d3a0a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9226a0ae61fe4139b1dfcc7b4f3c6048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cf5481a6d6b40c2b7b3407dd3986921",
      "placeholder": "​",
      "style": "IPY_MODEL_dd79760bc72c42beb92e6325725fd97f",
      "value": "Downloading: 100%"
     }
    },
    "930ce426da724d4a9cc83dec22f431d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dbb5cd3f295a46ccb5ebd422cb17dc7d",
       "IPY_MODEL_177c7b72f5494a77a4e99f784b04a140",
       "IPY_MODEL_90ae1f11ae42495c9ee6bdec12a2e6ed"
      ],
      "layout": "IPY_MODEL_2bea6b92eafb4b299164996975716a4c"
     }
    },
    "a15d541c346441d1990f63b46f3d685a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6b853d453374652a7108a1c7132dcfb",
      "max": 703051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_28ee415f653f4bca892b917cc4d59516",
      "value": 703051
     }
    },
    "a30e5173a933485bbaec0950b8144322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a67948a75e8c4753bb3be7f50cb69b2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aed68e0e0f8a4185956e6d277058c17b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6b853d453374652a7108a1c7132dcfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6fb9a445be74b2884194f1c059ea953": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bccf935bc9334a5793a681de4863654e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0e62fd3d424468ebd4f5b5415710b5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8afb472ba944bc4bb94192466d9bbc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cad249f40db1488e84ee61ea700340ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb24ad0a76de4e4ca3649809d40437b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf8b4c128350479f9823d3f3243752f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d2e0c03ae0eb47f5b2f90861e4fa67e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d46e63c37e7a46eabaae89892be902d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d63664f79e0646d1926203d08487237a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6f0184c751443a582da1bcaceb4222d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_249578c83d2840a19197ab99c0778379",
       "IPY_MODEL_90701ff27c864ffbabfffa91c3b3c37c",
       "IPY_MODEL_483fa124b73641ab90e962a8f07d9edc"
      ],
      "layout": "IPY_MODEL_90853cbd095c456b8f33f8efd0ef07ba"
     }
    },
    "d7c41db284d746b98f3f002bfc51cb1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbb5cd3f295a46ccb5ebd422cb17dc7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6ac9f486b274a83bdd3eede2dd441de",
      "placeholder": "​",
      "style": "IPY_MODEL_4bfd289d8eab426c8ab66bba4b470041",
      "value": "Downloading: 100%"
     }
    },
    "dd79760bc72c42beb92e6325725fd97f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2820c54debe46e686aeb2326f5f5225": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4276c9f591247589623b5ff20449496": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6db17f8a5ea4231be6c63952abc9be0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45a3a944205e4b439834ba591c73e6b0",
      "placeholder": "​",
      "style": "IPY_MODEL_cad249f40db1488e84ee61ea700340ee",
      "value": "Downloading: 100%"
     }
    },
    "e967a52bf1a343bb9395fdf4240a5d9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0fac156490a94fc6b2656312bb35c921",
       "IPY_MODEL_222def9d04434f529063233f364fa384",
       "IPY_MODEL_04e02a2cb7d146f79089f204ee834620"
      ],
      "layout": "IPY_MODEL_35f5205d66fb430f9c5456bbf12026f7"
     }
    },
    "f301256384f44e558759a3e478d4dd4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6ac9f486b274a83bdd3eede2dd441de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc3d15ead0ec4452b1ad06e029f66fa4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe47a6270e624095a23cdf87ceb48b27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
